\documentclass[11pt]{article}
\usepackage{acl02sub,url}
\title{NLTK: The Natural Language Toolkit}
\author{
Edward Loper and Steven Bird\\
Department of Computer and Information Science and Linguistic Data Consortium\\
University of Pennsylvania, Philadelphia, PA 19104-6389, USA
}
\summary{%
NLTK, the Natural Language Toolkit, is a suite of program modules,
tutorials and problem sets, providing ready-to-use CL courseware.
NLTK covers symbolic and statistical
NLP, and is interfaced to annotated corpora.
Students augment and replace existing components, learning
structured programming by example, and manipulating sophisticated
models from the outset.}
\paperid{Pxxxx}
\keywords{courseware, Python, corpora, keyword4?, keyword5?}
\contact{Edward Loper}
\conference{this paper has not been submitted to any other conferences}
\date{\today}

\begin{document}
\makeidpage
\maketitle

\begin{abstract}
Students in computational linguistics courses must often learn
a new programming language.  In some cases, such as when courses
are offered in linguistics departments,
the students may be learning to program for the very time.
In order to do interesting projects, it is usually necessary for
students to do many low-level ``housekeeping'' tasks.  At the same
time, teachers of computational linguistics courses sometimes feel
that they spend too much time teaching students to program, and not
enough time teaching the subject itself.  They may even avoid
programming assignments altogether.  However, we believe that it is
crucial for a first computational linguistics course to include a
strong practical component, in which students develop real programs to
solve real problems with real data.

Python is a new object-oriented scripting language which runs on all
platforms.  Python has been praised as ``executable pseudocode,'' since
programs are so easy to write.  Recently, we have been developing
NLTK, an open-source Natural Language Toolkit written in Python.
In this presentation, we will motivate, describe and demonstrate NLTK.

NLTK, the Natural Language Toolkit, is a suite of program modules,
tutorials and problem sets.  NLTK covers symbolic and statistical
natural language processing, and is interfaced to annotated corpora.
Students augment and replace existing NLTK components, learning
structured programming by example, and manipulating sophisticated
models from the outset.  Along with extensive documentation and
problem sets, NLTK provides self-contained, ready-to-use CL
courseware.
\end{abstract}

\section{Introduction}

Teachers of introductory courses on computational linguistics are
often faced with the challenge of setting up a practical programming
component for student assignments and projects.  This is difficult not
just because of the variety of data structures, but also because of
the diverse range of topics which may need to be included in the
syllabus.  A widespread practice is to teach multiple programming
languages, where each language provides native data structures and functions
that are a good fit for the task at hand (e.g. Prolog for parsing,
Perl for corpus processing, a finite-state toolkit for morphological
analysis).  By relying on the built-in features of various languages,
the teacher avoids having to develop a lot of software infrastructure.
An unfortunate consequence is that a significant part of the course
must be devoted to teaching these languages.  Further, many
interesting projects require the languages to be bridged, e.g. a
project that involved syntactic parsing of corpus data from a
morphologically rich language would involve all three languages
mentioned above (Perl for file I/O, format conversions and overall
program control, with calls out to a finite state toolkit for
morphological analysis and to a Prolog engine for parsing).  It is
clear that these considerable overheads and shortcomings warrant a
fresh approach.

Apart from the practical component, computational linguistics courses
may also depend on software for in-class
demonstrations.  This context calls for highly interactive graphical
user interfaces making it possible to view program state (e.g. the
chart of a chart parser), observe program execution step-by-step
(e.g. execution of a finite-state machine), and even make minor
modifications to programs in response to ``what if'' questions from
the class.  Because of these difficulties it is common to avoid live
demonstrations, and keep classes for theoretical presentations only.
Apart from being dull, this approach leaves students to solve
important practical problems on their own, or to deal with them less
efficiently in office hours.

In this paper we describe a new approach to the above challenges,
a streamlined and flexible way of organizing the practical component
of an introductory computational linguistics course.  We describe
NLTK, the Natural Language Toolkit, which we have developed in
conjunction with a course we have taught at the University of Pennsylvania.

OVERVIEW OF THE PAPER

All materials discussed here are available under an open
source license from \url{nltk.sf.net}.

\section{Choice of programming language}

The most basic step in setting up a practical component is choosing a
suitable programming language.  Here we list the desiderata that influence
our choice.

First, the language must have a shallow learning curve, so that novice
programmers get immediate rewards for their efforts.
Second, the language must support rapid prototyping and a short develop/test cycle;
an obligatory compilation step is a serious detraction.
Third, the code should be self-documenting,
with a transparent syntax and semantics.
Fourth, it should be easy to write structured programs, ideally object-oriented
but without the burden associated with languages like C++.
Finally, the language must have an easy-to-use graphics library to support
the development of simple graphical user interfaces.

In surveying the available languages, we believe that Python offers an especially good
fit to the above requirements.  Python is an object-oriented scripting language
developed by Guido van Rossum [REF] and available on all platforms
\url{www.python.org}.
Python offers a shallow learning curve by virtue of the
fact that it was designed to be easily learnt by children [REF].
As an interpreted language, Python is suitable for rapid prototyping.
Python code is exceptionally readable, and it has been praised as
``executable pseudocode.''
Python is an object-oriented language, but not punitively so, and it
is easy to encapsulate data and methods inside Python classes.
Finally, Python has an interface to the ``tk'' graphics toolkit, and
writing graphical interfaces is straightforward.

\section{Design criteria}


Several criteria must be considered in the design and implementation
of the toolkit.  The design criteria are divided into primary and
secondary criteria, and within those sections are listed in the order
of their importance.  A set of explicit non-requirements is also
given.  The toolkit is not expected to satisfy any of these
properties. 

\subsection{Primary Design Criteria}

\textbf{Ease of Use.} The primary purpose of the toolkit is to allow
students to concentrate on building NLP systems.  The more time
students must spend learning to use the toolkit, the less useful it
is.  

\textbf{Consistency.} The toolkit should use consistent data structures
and interfaces.

\textbf{Extensibility.} The toolkit should easily accommodate new
components, whether those components replicate or extend the toolkit's
existing functionality.  Thus, the toolkit's design should be modular,
with simple and well-defined interfaces between modules.  The toolkit
should also be structured in such a way that it is obvious where new
extensions would fit into the toolkit's infrastructure.

\textbf{Documentation.} The toolkit, its data structures, and its
implementation all need to be documented.  Three documentation types
are necessary: technical reports, to explain the toolkit's
design and implementation; tutorials, to teach students how to use the
toolkit to perform specific tasks; and reference documentation, to describe
every module, interface, class and method.  All nomenclature must be
carefully chosen and consistently used.

\subsection{Secondary Design Criteria}

\textbf{Simplicity.} The toolkit should structure the complexities of
building NLP systems, not hide them.  Therefore, each class defined by 
the toolkit should be simple enough that a student could implement it
by the time they finish the course.

\textbf{Modularity.} The interaction between different components of the
toolkit should be kept to a minimum.  In particular, it should be
possible to use complete individual projects using small parts of the
toolkit, without worrying about how they interact with the rest of the
toolkit.  This will allow students to learn to use the toolkit
incrementally throughout the course.  Modularity also makes it easier
to change or extend the toolkit.

\subsection{Non-Requirements}

\textbf{Comprehensiveness.} The toolkit is not intended to provide a
comprehensive set of tools.  Indeed, there should be a wide variety of 
ways in which students can extend the toolkit.

\textbf{Efficiency.} The toolkit does not need to be highly optimized for
runtime performance.  However, it should be efficient enough that
students can use their NLP systems to perform real tasks.

\textbf{Cleverness.} Clear designs and implementations are far preferable 
to ingenious yet indecipherable ones.

\section{Python Implementation}

The structure of the Python language directly affects the design and
implementation of the toolkit.  This section discusses how the design
of the toolkit is affected by the Python language.

\textbf{Interfaces.}
Python does not directly implement interfaces.  The toolkit
therefore implements interfaces as simple classes, all of whose methods 
raise \texttt{AssertionError} exceptions.  A description of the
functionality provided by the interface is contained in the
class's documentation string.  Each method's documentation string
specifies the behavior of that method.
In order to implement an interface, a class should include that
interface as one of its bases, and should override every
(non-optional) method defined by the interface.
Classes that define interfaces are named with a trailing ``I,'' such
as \texttt{TokenizerI} or \texttt{EventI}.

\textbf{Typing.}
Type checking is an important safety device, allowing programmers to
quickly locate errors in their code.  This is especially important for
novice programmers, who have less experience with debugging.  Every
function and method defined by the toolkit will check the types of its
its arguments.  Given the impact on performance, the level of type checking
will be adjustable.

\textbf{Advanced Language Features.}
The use of advanced language features and programming styles could
potentially make the toolkit much more difficult to use or to
understand.  The fewer language features that a student must learn in
order to use the toolkit, the faster they can start developing NLP
systems.  The language features used by
the toolkit are summarized by figure \ref{fig:feature}.

\begin{figure}
\begin{centering}
\begin{tabular}{|l|l|}
\hline
\textbf{Language Feature} & \textbf{Use} \\
\hline
Classes & used \\
Exceptions & error conditions only \\
Operator Overloading & used \\
Python 2.0 Features & used \\
Python 2.1 Features & not used \\
Function Arguments & minimal use \\
Lambda Functions & minimal use \\
Mapping and Filtering & not used \\
List Comprehensions & used \\
Tkinter & used \\
\hline
\end{tabular}\\
\end{centering}
\caption{Advanced language features used by NLTK.}
\label{fig:feature}
\end{figure}

\section{Basic modules}

\subsection{Tree}

\subsection{Tagger}

\subsection{Probability}

\section{Advanced modules}

\subsection{ChunkParser}

\subsection{ChartParser}

\subsection{FSA}

\subsection{Classifier}


\section{Evaluation}

How we used NLTK at Penn (including the competition).

Strengths and weaknesses

\section{Other approaches}

Java: \cite{Hammond02}
-- no obligation to cite this as it is unpublished
(and I haven't seen a copy).

\section{Conclusion}

Overview of the paper.

Upbeat conclusion.

Invitation to participate.

\bibliographystyle{acl}
\bibliography{submission}

\end{document}
