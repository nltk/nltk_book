<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN"
"../../docbook/sgml/docbook/xml-dtd-4.2/docbookx.dtd" [
<!-- Base URL for the reference & tutorial documentation -->
<!ENTITY refdoc "http://nltk.sourceforge.net/api/public">
<!ENTITY tutdoc "http://nltk.sourceforge.net/tutorial">

<!-- Index -->
<!ENTITY index SYSTEM "index.xml">

<!-- Prompts for Python code samples -->
<!ENTITY prompt "<prompt>&gt;</prompt><prompt>&gt;</prompt><prompt>&gt;</prompt>">
<!ENTITY prompt2 "<prompt>...</prompt>">
]>

<article>
  <articleinfo>
    <author><firstname>Steven</firstname><surname>Bird</surname></author>
    <authorinitials>sb</authorinitials>
    <author><firstname>Edward</firstname><surname>Loper</surname></author>
    <authorinitials>edl</authorinitials>
    <title>NLTK Tutorial: Parsing</title>
  </articleinfo>

  <section id="intro"> <title> Introduction </title>

<para>
In the context of computational modelling, a language is often viewed
as a set of well-formed sentences.  Sequences of words which are not
grammatical are excluded from this set.  Now, since there is no
upper-bound on the length of a sentence, the number of possible
sentences is unbounded.
For example, it is possible to add an unlimited amount of
material to a sentence by using <literal>and</literal> or by
chaining relative clauses, as illustrated in the following example
from a children's story:
</para>

<blockquote><para>
You can imagine Piglet's joy when at last the ship came in sight of
him. In after-years he liked to think that he had been in Very Great
Danger during the Terrible Flood, but the only danger he had really
been in was the last half-hour of his imprisonment, when Owl, who had
just flown up, sat on a branch of his tree to comfort him, and told
him a very long story about an aunt who had once laid a seagull's egg
by mistake, and the story went on and on, rather like this sentence,
until Piglet who was listening out of his window without much hope,
went to sleep quietly and naturally, slipping slowly out of the window
towards the water until he was only hanging on by his toes, at which
moment, luckily, a sudden loud squawk from Owl, which was really part
of the story, being what his aunt said, woke the Piglet up and just
gave him time to jerk himself back into safety and say, "How
interesting, and did she?"  when -- well, you can imagine his joy when
at last he saw the good ship, Brain of Pooh (Captain, C. Robin; Ist
Mate, P. Bear) coming over the sea to rescue him...
(from A.A. Milne <emphasis>In which Piglet is Entirely
Surrounded by Water</emphasis>)
</para></blockquote>

<para>
Given that the resources of a computer, however large, are still
finite, it is necessary to devise a finite description of this
infinite set.  Such descriptions are called grammars.  We have already
encountered this possibility in the context of regular expressions.
For example, the expression <literal>a+</literal> describes the
infinite set
<literal>{a, aa, aaa, aaaa, ...}</literal>.  Apart from their
compactness, grammars usually capture important properties of the
language being studied, and can be used to systematically map between
sequences of words and abstract representations of their meaning.
Thus, even if we were to
impose an upper bound on sentence length to ensure the language was
finite, we would still want to come up with a compact
representation in the form of a grammar.
</para>

<para>
A well-formed sentence of a language is more than an arbitrary
sequence of words from the language.  Certain kinds of words usually
go together.  For instance,
determiners like <literal>the</literal> are typically
followed by adjectives or nouns, but not by verbs.  Groups of words form
intermediate structures called phrases or constituents.  These
constituents can be identified using standard syntactic tests, such as
substitution, movement and coordination.  For example, if a sequence
of words can be replaced with a pronoun, then that sequence is likely
to be a constituent.  The following example illustrates this test:
</para>

<orderedlist><listitem><para>
  <orderedlist>
    <listitem><para><emphasis>Ordinary daily multivitamin and mineral
    supplements</emphasis> could help adults with diabetes fight
    off some minor infections</para></listitem>
    <listitem><para><emphasis>They</emphasis> could help adults with
    diabetes fight off some minor infections</para></listitem>
  </orderedlist>
</para></listitem></orderedlist>

<note><para>
Readers are referred to any introductory text on syntax for fuller
treatment of constituency, e.g. McCawley (1998) The Syntactic
Phenomena of English.
</para></note>

<para>
The structure of a sentence may be represented using a
phrase structure tree, in which the terminal symbols are the words of the sentence,
the pre-terminal symbols are parts of speech, and the remaining non-terminals
are syntactic constituents.  An example of such a tree is shown in
<xref linkend="parse_tree"/>.
</para>

<figure id="parse_tree"><title>Phrase Structure Tree</title>
<informaltable frame="all">
<tgroup cols="1"><tbody><row><entry>
<graphic fileref="images/parse_tree" scale="50"/>
</entry></row></tbody></tgroup></informaltable>
</figure>

<para>
A <emphasis>grammar</emphasis> is a formal system which specifies
which sequences of words are well-formed in the language, and which
provides one or more phrase structures for the sequence.  We will
focus our attention on a particular kind of grammar called a
<emphasis>context-free grammar</emphasis> (CFG),
which is a collection of productions of the form <literal>S &rarr; NP
VP</literal>.  (To be well-formed, each non-terminal node and its children
must correspond to such a production.)
</para>

<para>
A <emphasis>parser</emphasis> is a computational
system which processes input sentences according to the productions of the
grammar, and builds one or more constituent structures which conform
to the grammar.  We take a grammar to be a declarative specification
of well-formedness, and a parser to be a procedural interpretation of
the grammar.
In this chapter we will present context-free
grammars, and describe some simple parsers that work with them.
</para>

<!-- EXPAND THE ABOVE DISCUSSION -->

<para>
Parsing is important in linguistics and natural language processing
for a variety of reasons.  A parser permits a grammar to be evaluated
against a potentially large collection of test sentences, helping the
linguist to identify shortcomings in their analysis.  A parser can be
used as a model of psycholinguistic processing, and used to explain
the processing difficulties that humans have with certain syntactic
constructions (e.g. the so-called "garden path" sentences).  A parser
can serve as the first stage of processing natural language input for
a question-answering system.
</para>

  </section> <!-- Introduction -->

    <section id="overview"> <title> Linguistic Overview </title>

<!-- 
X.2 linguistic overview (for non-linguist readers)
    - how have linguists addressed the problem?
    - what are the shortcomings of the non-computational approach?

<para>
Parsing has a long and interesting history in computational
linguistics.
[NOTES: the perspective of early generative grammar;
early NLP approaches including ATNs and DCGs;
grammar formalisms and development environments.]
</para>
-->

    <para>
      Context-free grammars: CFG productions and
      and their interpretation.
    </para>

    <para>
      Discussion about how CFGs are created by hand.
    </para>

    <para>A simple grammar:
    </para>

<programlisting>
S &rarr; NP VP
NP &rarr; Det N
NP &rarr; Det N PP
VP &rarr; V NP PP
VP &rarr; V NP
VP &rarr; V
PP &rarr; P NP

NP &rarr; 'I'
Det &rarr; 'the'
Det &rarr; 'a'
N &rarr; 'man'
V &rarr; 'saw'
P &rarr; 'in'
N &rarr; 'park'
P &rarr; 'with'
N &rarr; 'dog'
N &rarr; 'telescope'
</programlisting>

<para>
Shortcomings of this approach: unreliable, doesn't scale,
complex interactions amongst productions makes manual debugging
almost impossible.  Consequently linguists are unable to
work with large-coverage grammars.
</para>

    </section> <!-- Linguistic Overview -->

    <section id="approaches"> <title> Computational Approaches to Parsing </title>

<!-- To do: general introduction to TD and BU -->

<!--
X.3 computational model (gentle for linguistics ugrads)
    - what are some good data structures and algorithms?
    - just pick one or two approaches, not encyclopedic
    - NLTK demo - watch the execution of the algorithm
      (screen shots to show execution, side bars to say how
       to do it)
-->

      <section id="approaches.rd"> <title> Recursive Descent Parsing </title>

<para>
The simplest kind of parser interprets the grammar as a
specification of how to break a high-level goal into several
lower-level subgoals.  The top-level goal is to
find an <literal>S</literal>.  The <literal>S &rarr; NP
VP</literal> production permits the parser to replace this goal
with two subgoals: find an <literal>NP</literal>, then find
a <literal>VP</literal>.  Each of these subgoals can be
replaced in turn by sub-sub-goals, using productions that have
<literal>NP</literal> and <literal>VP</literal> on their
left-hand side.  Eventually, this expansion process leads to
subgoals such as: find the word
<literal>telescope</literal>.  Such subgoals can be directly
compared against the input string, and succeed if the next
word is matched.
</para>

<para>
The recursive descent parser builds a parse tree during the
above process.  With the initial goal (find an
<literal>S</literal>), the <literal>S</literal> root node is
created.  As the above process recursively expands its goals
using the productions of the grammar, the parse tree is extended downwards
(hence the name <emphasis>recursive descent</emphasis>).  We can see this
in action using the parser demonstration <literal>nltk.draw.rdparser</literal>.
To run this demonstration, use the following commands:
</para>

<programlisting>
&prompt;<command> from nltk.draw.rdparser import demo</command>
&prompt;<command> demo()</command>
</programlisting>

<para>
Six stages of the execution of this parser are shown in
<xref linkend="rdparser"/>.
</para>

<figure id="rdparser"><title>Six Stages of a Recursive Descent Parser: initial, after two productions,
after matching "the", failing to match "man", completed parse, backtracking <emphasis>BROKEN!</emphasis>
</title>
<informaltable frame="all">
<tgroup cols="2"><tbody><row><entry>
<graphic fileref="images/rdparser1" scale="36"/>
</entry><entry>
<graphic fileref="images/rdparser2" scale="36"/>
</entry></row><row><entry>
<graphic fileref="images/rdparser3" scale="36"/>
</entry><entry>
<graphic fileref="images/rdparser4" scale="36"/>
</entry></row><row><entry>
<graphic fileref="images/rdparser5" scale="36"/>
</entry><entry>
<graphic fileref="images/rdparser6" scale="36"/>
</entry></row></tbody></tgroup></informaltable>
</figure>

<para>Discussion: choosing which of several possible productions to apply;
backtracking (NB the rdparser code has a bug that prevents it
from backtracking properly.)  Discuss termination.</para>

<para>Problems with recursive descent parsing:
considers structures and words that are not attested;
backtracking may discard parsed constituents that need to be rebuilt;
for example, backtracking over <literal>VP &rarr; V NP</literal>
will discard the structures created for the
<literal>V</literal> and <literal>NP</literal> non-terminals.  If the parser then proceeds
with <literal>VP &rarr; V NP PP</literal>, then the structures for the
<literal>V</literal> and <literal>NP</literal> must be created again.
</para>

<para>
Recursive descent parsing is a kind of <emphasis>top-down
parsing</emphasis>.  These use the grammar to
<emphasis>predict</emphasis> what the input will be, before
inspecting any input.  However, since the input is available
to the parser all along, it would be more sensible to
consider the input sentence from the very beginning.  Such
an approach is called <emphasis>bottom-up
parsing</emphasis>, and is the topic of the next section.
</para>

</section>
<section id="approaches.sr"> <title> Shift-Reduce Parsing </title>

<para>
The simplest kind of bottom-up parsing is known as shift-reduce
parsing.  The parser repeadly pushes the next input word onto a stack;
this is the <emphasis>shift</emphasis> operation.  If the top
<replaceable>n</replaceable> items on the stack match the
<replaceable>n</replaceable> items on the right-hand side of some
production, then they are all popped off the stack, and the item on
the left-hand side of the production is pushed on the stack.  This
replacement of the top <replaceable>n</replaceable> items with a
single item is the <emphasis>reduce</emphasis> operation.  The parser finishes
when all the input is consumed and there is only one item remaining on the stack,
a parse tree with an <literal>S</literal> node as its root.
</para>

<!--
To do: add examples and motivate more - what are we doing with
bottom up - find little pieces and expand...
-->

<note><para>
Note that the reduce operation may only be applied to the top of the stack.
Reducing items lower in the stack must be done before later items are pushed onto
the stack.
</para></note>

<para>
The shift-reduce parser builds a parse tree during the above process.
If the top of stack holds the word <literal>dog</literal> and if the
grammar has a production <literal>N &rarr; dog</literal> then the reduce
operation causes the word to be replaced with the parse tree for this
production.  For convenience we will represent this tree as
<literal>N(dog)</literal>.  At a later stage, if the top of the stack
holds two items <literal>Det(the) N(dog)</literal> and if the grammar
has a production <literal>NP &rarr; Det N</literal> then the reduce operation
causes these two items to be replaced with <literal>NP(Det(the),
N(dog))</literal>.  This process continues until a parse tree for the
entire sentence has been constructed.  We can see this in action using
the parser demonstration <literal>nltk.draw.srparser</literal>.  To
run this demonstration, use the following commands:
</para>

<programlisting>
&prompt;<command> from nltk.draw.srparser import demo</command>
&prompt;<command> demo()</command>
</programlisting>

<para>
Six stages of the execution of this parser are shown in
<xref linkend="srparser"/>.
</para>

<!--
To do: use letter identifiers for subfigures.
-->

<figure id="srparser"><title>Six Stages of a Shift-Reduce Parser: initial, after one shift,
after shift reduce shift reduce, after recognizing the second NP, complex NP,
final step</title>
<informaltable frame="all">
<tgroup cols="2"><tbody><row><entry>
<graphic fileref="images/srparser1" scale="30"/>
</entry><entry>
<graphic fileref="images/srparser2" scale="30"/>
</entry></row><row><entry>
<graphic fileref="images/srparser3" scale="30"/>
</entry><entry>
<graphic fileref="images/srparser4" scale="30"/>
</entry></row><row><entry>
<graphic fileref="images/srparser5" scale="30"/>
</entry><entry>
<graphic fileref="images/srparser6" scale="30"/>
</entry></row></tbody></tgroup></informaltable>
</figure>

<para>
A shift-reduce parser may fail to parse the sentence, even though the
sentence is well-formed according to the grammar.  In such cases,
there are no remaining input words to shift, and there is no way to
reduce the remaining items on the stack, as exemplified in the left
example in <xref linkend="sr-conflict"/>.  The parser entered this
blind alley at an earlier stage shown in the middle example in
<xref linkend="sr-conflict"/>, when it reduced instead of shifted.
This situation is called a <emphasis>shift-reduce conflict</emphasis>.
At another possible stage of processing shown in the right example
in <xref linkend="sr-conflict"/>, the parser must choose between two
possible reductions, both matching the top items on the stack:
<literal>V &rarr; V NP PP</literal> or <literal>NP &rarr; NP PP</literal>.
This situation is called a <emphasis>reduce-reduce conflict</emphasis>.
</para>

<!--
To do: diagram showing search tree with success and failure.
-->

<figure id="sr-conflict"><title>Conflict in Shift-Reduce Parsing</title>
<informaltable frame="all">
<tgroup cols="3"><tbody><row><entry>
<graphic fileref="images/srparser7" scale="24"/>
</entry><entry>
<graphic fileref="images/srparser8" scale="24"/>
</entry><entry>
<graphic fileref="images/srparser9" scale="24"/>
</entry></row></tbody></tgroup></informaltable>
</figure>

<para>
Shift-reduce parsers may implement policies for resolving such
conflicts.  For example, they may address shift-reduce conflicts by
shifting only when no reduces are possible, and they may address reduce-reduce conflicts
by favouring the reduce operation that removes the most items from the stack.
No such policies are failsafe however.
</para>

<para>
The advantages of shift-reduce parsers over recursive descent parsers is that they
only build structure that corresponds to the words in the input.  Furthermore, they
only build each substructure once, e.g. <literal>NP(Det(the), N(man))</literal> is
only built and pushed onto the stack a single time, regardless of whether it will later
be used by the <literal>V &rarr; V NP PP</literal> reduction or the <literal>NP &rarr; NP PP</literal>
reduction.
</para>

</section>
</section>

    <section id="advanced"> <title> Advanced Topics in Parsing (optional) </title>

    <warning><para> Some of the following is out of
    date.  See the <ulink
    url="&refdoc;/nltk.parser-module.html">reference
    documentation for <literal>nltk.parser</literal></ulink> for more
    up-to-date information. </para></warning>

    <para>Parsing as a search problem.  Finding the right parse.</para>

<para>late closure etc</para>


<!--
X.4 advanced topics (optional)
    - other approaches, evaluation, problems
    - challenges for particular languages / language families
    - research questions
-->

    </section>

    <section id="nltk"> <title> Parsing in NLTK </title>

    <para></para>

<!--
X.5 implementation
    - how does NLTK do it?
    - simple problems and worked solutions
    - suggested projects (e.g. for your MSc students)
-->

    <section id="nltk.grammars">
      <title> Context Free Grammars </title>

      <para> The <ulink url="&refdoc;/nltk.cfg-module.html"
      ><literal>nltk.cfg</literal></ulink> module defines a set of
      classes that are used to define context free grammars: </para>

      <itemizedlist>
        <listitem><para> The <ulink
        url="&refdoc;/nltk.cfg.Nonterminal-class.html"
        ><literal>Nonterminal</literal></ulink> class is used to
        represent nonterminals.</para>
        </listitem>
        <listitem><para> The <ulink
        url="&refdoc;/nltk.cfg.CFGProduction-class.html"
        ><literal>CFGProduction</literal></ulink> class is used to
        represent CFG productions.</para>
        </listitem>
        <listitem><para> The <ulink
        url="&refdoc;/nltk.cfg.CFG-class.html"
        ><literal>CFG</literal></ulink> class is used to
        represent CFGs.</para>
        </listitem>
      </itemizedlist>

      <section id="nltk.grammars.nonterminal">
        <title> Nonterminals </title>

        <para> <ulink url="&refdoc;/nltk.cfg.Nonterminal-class.html"
        ><literal>Nonterminal</literal></ulink> is a simple class
        that's used to let NLTK distinguish terminals from
        nonterminals.  Each <literal>Nonterminal</literal> is defined
        by a <glossterm>symbol</glossterm>, which is represented by a
        case-sensitive string.  Typical symbols for
        <literal>Nonterminals</literal> are <literal>"S"</literal>
        (for sentence) and <literal>"NP"</literal> (for noun phrases).
        To construct a <literal>Nonterminal</literal>, use the <ulink
        url="&refdoc;/nltk.cfg.Nonterminal-class.html#__init__"
        ><literal>Nonterminal</literal> constructor</ulink>: </para>

<programlisting>
&prompt; <command>from nltk.cfg import *</command>
&prompt; <command>S = Nonterminal('S')</command>
&lt;S&gt;
&prompt; <command>NP = Nonterminal('NP')</command>
&lt;NP&gt;
</programlisting>

        <!-- Mention the symbol() method? -->
        <!-- Mention division of nonterminal? -->

        <para> If you are defining many nonterminals at once, you can
        use the <ulink
        url="&refdoc;/nltk.cfg-module.html#nonterminals"
        ><literal>nonterminals()</literal></ulink> function.  This
        function takes a string containing a list of symbol names, and
        returns a list of <literal>Nonterminals</literal> constructed
        from those symbol names: </para>

<programlisting>
&prompt; <command>VP, Adj, V, N = nonterminals('VP, Adj, V, N')</command>
(&lt;VP&gt;, &lt;PP&gt;, &lt;V&gt;, &lt;N&gt;, &lt;P&gt;)          
</programlisting>

        <para> When using the <literal>nonterminals()</literal>
        function, you should be always be careful to make sure that
        the order of the variables you define matches the order of the
        nonterminals in the string.</para>
      
      </section> <!-- Nonterminals -->

      <section id="nltk.grammars.cfgproductions">
        <title> Productions </title>

        <para> CFG productions are represented with the <ulink
        url="&refdoc;/nltk.cfg.CFGProduction-class.html"
        ><literal>CFGProduction</literal></ulink> class.  Each
        <literal>CFGProduction</literal> specifies that a nonterminal
        (the <glossterm>left-hand side</glossterm>) can be expanded to
        a sequence of terminals and nonterminals (the
        <glossterm>right-hand side</glossterm>).
        <literal>CFGProductions</literal> are created with the <ulink
        url="&refdoc;/nltk.cfg.CFGProduction-class.html#__init__"
        ><literal>CFGProducition</literal> constructor</ulink>, which
        takes a nonterminal left-hand side, and zero or more terminals
        and nonterminals for the right-hand side. </para>
        
<programlisting>
&prompt; <command>prod1 = CFGProduction(S, NP, VP)</command>
[Production: S -&gt; NP V]
&prompt; <command>prod2 = CFGProduction(NP, 'the', Adj, N)</command>
[Production: NP -&gt; 'the' Adj N]
</programlisting>

        <para> The right-hand side may contain any number of elements.
        In particular, for so-called <glossterm>epsilon
        productions</glossterm>, the right-hand side is empty.  When parsing
        natural language, epsilon productions are often used for
        <glossterm>traces</glossterm>, which mark the position from
        which a constituant moved:</para>

<programlisting>
&prompt; <command>trace = Nonterminal('t')</command>
&lg;t&gt;

<emphasis># A trace does not generate any text. </emphasis>
&prompt; <command>prod3 = CFGProduction(trace)</command>
[Production: t -&gt;]
</programlisting>

      </section> <!-- CFGProduction -->

      <section id="nltk.grammars.cfg">
        <title> CFGs </title>

        <para> Context free grammars are encoded by the <ulink
        url="&refdoc;/nltk.cfg.CFG-class.html"
        ><literal>CFG</literal></ulink> class.  A
        <literal>CFG</literal> consists of a special
        <glossterm>start</glossterm> nonterminal, and an ordered list
        of productions.  <literal>CFGs</literal> are created with the
        <ulink url="&refdoc;/nltk.cfg.CFG-class.html#__init__"
        ><literal>CFG</literal> constructor</ulink>: </para>

<programlisting>
&prompt; <command>cfg = CFG(S, [prod1, prod2, prod3])</command>
&lt;CFG with 3 productions&gt;
</programlisting>

        <para> A CFG's start state is returned by the <ulink
        url="&refdoc;/nltk.cfg.CFG-class.html#start"
        ><literal>start</literal></ulink> method; and its list of
        productions is returned by the <ulink
        url="&refdoc;/nltk.cfg.CFG-class.html#productions"
        ><literal>productions</literal></ulink> method: </para>
        
<programlisting>
&prompt; <command>cfg.start</command>
&lt;S&gt;
&prompt; <command>cfg.productions</command>
[ [Production: S -&gt; NP V],
  [Production: NP -&gt; 'the' Adj N],
  [Production: t -&gt;] ]
</programlisting>

      </section> <!-- CFG -->
    </section> <!-- Context Free Grammars -->

    <section id="nltk.tree">
      <title> Trees </title>

      <para> The <ulink url="&refdoc;/nltk.tree-module.html"
      ><literal>nltk.tree</literal></ulink> module defines classes and
      functions for working with trees.  NLTK distinguishes between
      tree types (abstract trees without context) ant tree tokens
      (individual occurances of trees).  Tree types are represented
      with the <ulink url="&refdoc;/nltk.tree.Tree-class.html"
      ><literal>Tree</literal></ulink> class; and tree tokens are
      represented with the <ulink
      url="&refdoc;/nltk.tree.TreeToken-class.html"
      ><literal>TreeToken</literal></ulink> class.  </para>

      <note>
        <para> The <literal>nltk.tree</literal> module currently has
        no direct support for representing movement, traces, and
        co-indexing.  We plan to extend the class to support these
        features more fully in the future. </para>
      </note>

      <section id="nltk.tree.treetype">
        <title> Tree Types </title>

        <para> Tree types are encoded with the <ulink
        url="&refdoc;/nltk.tree.Tree-class.html"
        ><literal>Tree</literal></ulink> class.  A
        <literal>Tree</literal> consists of a <glossterm>node
        value</glossterm> and one or more
        <glossterm>children</glossterm>. </para>

        <itemizedlist>
          <listitem> <para> The node value is a string containing the
          tree's constituent type (e.g., "NP" or "VP").
          </para></listitem>

          <listitem> <para> The children encode the hierarchical
          contents of the tree.  Each child is either a subtree or a
          word type. </para>
          </listitem>
        </itemizedlist>
    
        <note>
          <para> Although the <literal>Tree</literal> class is usually
          used for encoding syntax trees, it can be used to encode
          <emphasis>any</emphasis> homogenous hierarchical structure
          that spans a text (such as morphological structure or
          discourse structure).  In the general case, leaves and node
          values do not have to be strings. </para>
        </note>

        <para> A <literal>Tree</literal> with node value
        <replaceable>n</replaceable> and children
        <replaceable>c<subscript>1</subscript></replaceable>,
        <replaceable>c<subscript>2</subscript></replaceable>, ...
        <replaceable>c<subscript>n</subscript></replaceable> is
        written <literal>(<replaceable>n</replaceable>:
        <replaceable>c<subscript>1</subscript></replaceable>
        <replaceable>c<subscript>2</subscript></replaceable> ...
        <replaceable>c<subscript>n</subscript></replaceable>)</literal>.
        <literal>Tree</literal>s are created with the <ulink
        url="&refdoc;/nltk.tree.Tree-class.html#__init__"
        ><literal>Tree constructor</literal></ulink>, which takes a
        node value and zero or more children: </para>

<programlisting>
<emphasis># A tree with one child (a word type):</emphasis>
&prompt;<command> tree1 = Tree('NP', 'John')</command>
('NP': 'John')

<emphasis># A tree with two children (both of which are word types):</emphasis>
&prompt;<command> tree2 = Tree('NP', 'the', 'man')</command>
('NP': 'the' 'man')

<emphasis># A tree with two children (a word type and a subtree):</emphasis>
&prompt;<command> tree3 = Tree('VP', 'saw', tree2)</command>
('VP': 'saw' ('NP': 'the' 'man'))
</programlisting>

        <para> A <literal>Tree</literal>'s node value is accessed with
        the <ulink url="&refdoc;/nltk.tree.Tree-class.html#node"
        ><literal>node</literal></ulink> method: </para>

<programlisting>
&prompt;<command> tree1.node()</command>
'NP'
</programlisting>

        <para> A <literal>Tree</literal>'s children are accessed with
        standard sequence operators: </para>

<programlisting>
&prompt;<command> tree3[0]</command>
'saw'
&prompt;<command> tree3[1]</command>
('NP': 'the' 'man')
&prompt;<command> len(tree3)</command>
2
&prompt;<command> 'saw' in tree3</command>
1
&prompt;<command> for child in tree3: </command>
&prompt2;<command>     print child</command>
saw 
('NP': 'the' 'man')
&prompt;<command> [child.upper() for child in tree2] </command>
['THE', 'MAN']
</programlisting>

        <para> The printed representation for complex
        <literal>Tree</literal>s can be difficult to read.  In these
        cases, the <ulink
        url="&refdoc;/nltk.tree.Tree-class.html#draw"
        ><literal>draw</literal></ulink> method can be very useful.
        This method opens a new window, containing a graphical
        representation of the tree.  </para>

<programlisting>
&prompt;<command> tree3.draw()</command>
</programlisting>

        <para> The tree display window allows you to zoom in and out;
        to collapse and expand subtrees; and to print the graphical
        representation to a postscript file. </para>

        <para> If you'd like to compare multiple trees in a single
        window, you can use the <ulink
        url="&refdoc;/nltk.draw.tree-module.html#draw_trees"
        ><literal>draw_trees()</literal></ulink> method, from the
        <ulink url="&refdoc;/nltk.draw.tree-module.html"
        ><literal>nltk.draw.tree</literal> module: </ulink> </para>

<programlisting>
&prompt;<command> from nltk.draw.tree import draw_trees</command>
&prompt;<command> draw_trees(tree1, tree2, tree3)</command>
</programlisting>

        <para> The <literal>Tree</literal> class implements a number
        of other useful methods.  See the <ulink
        url="&refdoc;/nltk.tree.Tree-class.html"
        ><literal>Tree</literal> reference documentation</ulink> for
        more information about these methods. </para>

<programlisting>
&prompt;<command> tree3.leaves()</command>
('saw', 'the', 'man')
&prompt;<command> tree3.height()</command>
3
&prompt;<command> tree3.nodes()</command>
('VP': ('NP':))
</programlisting>

        <!-- Mention tree positions? -->
        
      </section> <!-- Tree Types -->

      <section id="nltk.tree.treetoken">
        <title> Tree Tokens </title>

        <para> Tree tokens are encoded with the <ulink
        url="&refdoc;/nltk.tree.TreeToken-class.html"
        ><literal>TreeToken</literal></ulink> class.  Like
        <literal>Trees</literal>, each <literal>TreeToken</literal>
        consists of a node value and a list of children.  However,
        <literal>TreeToken</literal>s children contain word
        <emphasis>tokens</emphasis> instead of word types. </para>

        <para> <literal>TreeTokens</literal> support all of the methods
        defined for <literal>Trees</literal>.  In addition,
        <literal>TreeToken</literal> defines the standard <literal>Token</literal>
        methods: </para>

        <itemizedlist>
          <listitem> <para> The <ulink
          url="&refdoc;/nltk.tree.TreeToken-class.html#type"
          ><literal>type</literal></ulink> method returns a
          <literal>TreeToken</literal>'s type (a <literal>Tree</literal>). </para>
          </listitem>
          <listitem> <para> The <ulink
          url="&refdoc;/nltk.tree.TreeToken-class.html#loc"
          ><literal>loc</literal></ulink> method returns a
          <literal>TreeToken</literal>'s location.</para>
          </listitem>
        </itemizedlist>
              
      </section> <!-- Tree Tokens -->

      <section id="nltk.tree.reading">
        <title> Reading Trees from the Treebank Corpus </title>

        <para> The <ulink url="&refdoc;/nltk.corpus-module.html"
        ><literal>nltk.corpus</literal></ulink> module defines the
        <ulink url="&refdoc;/nltk.corpus-module.html#treebank"
        ><literal>treebank</literal></ulink> corpus, which contains a
        collection of hand-annotated parse trees for English
        text. </para> <!-- Add a reference to LDC here? -->

<programlisting>
&prompt;<command> from nltk.corpus import treebank</command>

<emphasis># Get a list of the files in the corpus. </emphasis>
&prompt;<command> treebank.filenames()</command>
['wsj_0001.prd', 'wsj_0002.prd', 'wsj_0003.prd', ...]

<emphasis># Read the first file as a list of TreeTokens. </emphasis>
&prompt;<command> treebank.tokenize('wsj_0001.prd')</command>
[ ('S': ('NP-SBJ': ('NP': 'Pierre' 'Vinken') ...)
        ('VP': will ...)),
  ('S': ('NP-SBJ': 'Mr.' 'Vinken')
        ('VP': is ...)) ]
</programlisting>
        
      </section> <!-- Reading Trees -->

  </section> <!-- Encoding Syntax Trees -->

  <section id="nltk.interface"> <title> The Parser Interface </title>

    <para>The <ulink url="&refdoc;/nltk.parser-module.html"
    ><literal>parser</literal></ulink> module defines the <ulink
    url="&refdoc;/nltk.parser.ParserI-class.html"
    ><literal>ParserI</literal></ulink> interface, which defines the
    set of methods which all parsers should support.  The
    <literal>ParserI</literal> interface defines two methods: </para>

      <!-- I say "n best" and "in descending order of quality" here,
      but so far we've only talked about grammars with no notion of
      parse quality.  Will that be confusing? -->
      <itemizedlist>
        <listitem><para> The <ulink
        url="&refdoc;/nltk.parser.ParserI-class.html#parse"
        ><literal>parse</literal></ulink> method returns the single
        best parse for a given text.  The text is represented as a
        list of <literal>Tokens</literal>.  If no parses are found for the
        given text, then <literal>parse</literal> returns
        <literal>None</literal>. </para>
        </listitem>
        <listitem> <para> The <ulink
        url="&refdoc;/nltk.parser.ParserI-class.html#parse_n"
        ><literal>parse_n</literal></ulink> method returns a list of
        the <emphasis>n</emphasis> best parses for the given text,
        sorted in descending order of quality (or all parses, if the
        text has less than <emphasis>n</emphasis> parses).
        <emphasis>n</emphasis> is an optional argument; if it is not
        specified, then <literal>parse_n</literal> returns all parses
        for the text. </para>
        </listitem>
      </itemizedlist>

      <para> For example, here is what the recursive descent parser
      generates for a simple sentence and grammar: </para>
        
<programlisting>
<emphasis># Tokenize a simple sentence </emphasis>
&prompt;<command> sentence = 'I saw a man in the park' </command>
&prompt;<command> text = WSTokenizer().tokenize(sentence) </command>
        
<emphasis># Build a parser </emphasis>
&prompt;<command> from nltk.parser import RecursiveDescentParser </command>
&prompt;<command> parser = RecursiveDescentParser(my_cfg) </command>
        
<emphasis># Get one parse. </emphasis>
&prompt;<command> parser.parse(text)</command>
('S': ('NP': 'I')
      ('VP': ('V': 'saw')
             ('NP': ('Det': 'a') ('N': 'man'))
             ('PP': ('P': 'in') ('NP': ('Det': 'the')
                                       ('N': 'park')))))@[0w:7w]

<emphasis># Get all parses. </emphasis>
&prompt;<command> parser.parse_n(text)</command>
[('S': ('NP': 'I')
       ('VP': ('V': 'saw')
              ('NP': ('Det': 'a') ('N': 'man'))
              ('PP': ('P': 'in') ('NP': ('Det': 'the')
                                        ('N': 'park')))))@[0w:7w],
 ('S': ('NP': 'I')
       ('VP': ('V': 'saw')
              ('NP': ('Det': 'a')
                     ('N': 'man')
                     ('PP': ('P': 'in')
                            ('NP': ('Det': 'the')
                                   ('N': 'park'))))))@[0w:7w]]
</programlisting>

    </section> <!-- The parser interface -->
    
    <section id="nltk.ShiftReduceParser">
      <title>The Shift Reduce Parser </title>

      <para> The <ulink url="&refdoc;/nltk.parser-module.html"
      ><literal>nltk.parser</literal></ulink> module defines <ulink
      url="&refdoc;/nltk.parser.ShiftReduceParser-class.html"
      ><literal>ShiftReduceParser</literal></ulink>, a simple
      non-backtracking implementation of a bottom-up shift-reduce
      parser.  Since this parser does not implement any backtracking,
      it is not guaranteed to find a parse for a text, even if one
      exists.  Furthermore, it will always find at most one parse,
      even if more parses exist. </para>

      <para> Shift reduce parsers are created from
      <literal>CFGs</literal> by the <ulink
      url="&refdoc;/nltk.parser.ShiftReduceParser-class.html#__init__"
      ><literal>ShiftReduceParser</literal> constructor</ulink>.  The
      constructor takes an optional argument <literal>trace</literal>.
      If <literal>trace</literal> is greater than zero, then the
      parser will describe the steps that it takes as it parses a
      text.  Higher values of <literal>trace</literal> produce more
      verbose descriptions.
      </para>

<programlisting>
&prompt;<command> from nltk.parser import * </command>

<emphasis># Construct a new parser from my_cfg </emphasis>
&prompt;<command> sr_parser = ShiftReduceParser(my_cfg) </command>

<emphasis># Construct a parser that will print trace output. </emphasis>
&prompt;<command> tracing_sr_parser = ShiftReduceParser(my_cfg, 5) </command>
</programlisting>

      <para> The following example shows the trace output generated by
      <literal>tracing_parser</literal> on a simple sentence: </para>
          
<programlisting>
&prompt;<command> text = WSTokenizer().tokenize('I saw a man') </command>
&prompt;<command> tracing_sr_parser.parse(text)</command>
Parsing 'I saw a man'
    [ * 'I' 'saw' 'a' 'man']
Shift 'I'@[0w]:
    [ 'I' * 'saw' 'a' 'man']
Reduce &lt;NP&gt; &lt;- 'I'
    [ &lt;NP&gt; * 'saw' 'a' 'man']
Shift 'saw'@[1w]:
    [ &lt;NP&gt; 'saw' * 'a' 'man']
Reduce &lt;V&gt; &lt;- 'saw'
    [ &lt;NP&gt; &lt;V&gt; * 'a' 'man']
Shift 'a'@[2w]:
    [ &lt;NP&gt; &lt;V&gt; 'a' * 'man']
Reduce &lt;Det&gt; &lt;- 'a'
    [ &lt;NP&gt; &lt;V&gt; &lt;Det&gt; * 'man']
Shift 'man'@[3w]:
    [ &lt;NP&gt; &lt;V&gt; &lt;Det&gt; 'man' * ]
Reduce &lt;N&gt; &lt;- 'man'
    [ &lt;NP&gt; &lt;V&gt; &lt;Det&gt; &lt;N&gt; * ]
Reduce &lt;NP&gt; &lt;- &lt;Det&gt; &lt;N&gt;
    [ &lt;NP&gt; &lt;V&gt; &lt;NP&gt; * ]
Reduce &lt;VP&gt; &lt;- &lt;V&gt; &lt;NP&gt;
    [ &lt;NP&gt; &lt;VP&gt; * ]
Reduce &lt;S&gt; &lt;- &lt;NP&gt; &lt;VP&gt;
    [ &lt;S&gt; * ]
('S': ('NP': 'I')
      ('VP': ('V': 'saw')
             ('NP': ('Det': 'a') ('N': 'man'))))@[0w:4w]
</programlisting>

      <para> NLTK also defines a graphical demonstration tool for the
      shift reduce parser: </para>
        
<programlisting>
&prompt; <command>import nltk.draw.srparser</command>
&prompt; <command>nltk.draw.srparser.demo</command>
</programlisting>

    </section> <!-- ShiftReduceParser -->

    <section id="nltk.RecursiveDescentParser">
      <title>The Recursive Descent Parser </title>

      <para> The <ulink url="&refdoc;/nltk.parser-module.html"
      ><literal>nltk.parser</literal></ulink> module defines <ulink
      url="&refdoc;/nltk.parser.RecursiveDescentParser-class.html"
      ><literal>RecursiveDescentParser</literal></ulink>, a simple
      recursive implementation of a top-down parser.  Unlike the
      shift-reduce parser, this parser is guaranteed to find all
      parses for a sentence.  But because it's a simple recursive
      top-down parser, it can enter an infinite loop if the grammar
      contains a left-recursive production. </para>

      <para> Recursive descent parsers are created from
      <literal>CFGs</literal> by the <ulink
      url="&refdoc;/nltk.parser.RecursiveDescentParser-class.html#__init__"
      ><literal>RecursiveDescentParser</literal> constructor</ulink>.
      The constructor takes an optional argument
      <literal>trace</literal>.  As with the shift reduce parser, this
      value specifies how verbosely the parser should describe the
      steps that it takes as it parses a text.
      </para>

<programlisting>
&prompt;<command> from nltk.parser import * </command>

<emphasis># Construct a new parser from my_cfg </emphasis>
&prompt;<command> rd_parser = RecursiveDescentParser(my_cfg) </command>

<emphasis># Construct a parser that will print trace output. </emphasis>
&prompt;<command> tracing_rd_parser = RecursiveDescentParser(my_cfg, 2) </command>
</programlisting>

      <para> The following example shows the trace output generated by
      <literal>tracing_rd_parser</literal> on a simple sentence: </para>
          
<programlisting>
&prompt;<command> text = WSTokenizer().tokenize('I saw a man') </command>
&prompt;<command> tracing_parser.parse(text)</command>
Parsing 'I saw a man'
Start:
    [ * &lt;S&gt; ]
Expand: S -&gt; NP VP
    [ * &lt;NP&gt; &lt;VP&gt; ]
Expand: NP -&gt; Det N
    [ * &lt;Det&gt; &lt;N&gt; &lt;VP&gt; ]
Expand: Det -&gt; 'the'
    [ * 'the' &lt;N&gt; &lt;VP&gt; ]
Backtrack: 'I'@[0w] match failed
Expand: Det -&gt; 'a'
    [ * 'a' &lt;N&gt; &lt;VP&gt; ]
Backtrack: 'I'@[0w] match failed
<emphasis>...</emphasis>
Expand: N -> 'man'
    [ 'I' 'saw' 'a' * 'man' ]
Match: 'man'@[3w]
    [ 'I' 'saw' 'a' 'man' ]
GOOD PARSE:
    [ 'I' 'saw' 'a' 'man' ]
('S': ('NP': 'I')
      ('VP': ('V': 'saw')
             ('NP': ('Det': 'a') ('N': 'man'))))@[0w:4w]
</programlisting>

      <para> NLTK also defines a graphical demonstration tool for the
      recursive descent parser: </para>
        
<programlisting>
&prompt; <command>import nltk.draw.rdparser</command>
&prompt; <command>nltk.draw.rdparser.demo</command>
</programlisting>

    </section> <!-- RecursiveDescentParser -->

  </section> <!-- Parsing in NLTK -->

  &index;
</article>
