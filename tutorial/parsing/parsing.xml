<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN" [
<!ENTITY prompt "<prompt>&gt;</prompt><prompt>&gt;</prompt><prompt>&gt;</prompt>">
<!ENTITY prompt2 "<prompt>...</prompt>">
]>

<article>
  <articleinfo>
    <author><firstname>Steven</firstname><surname>Bird</surname></author>
    <authorinitials>sb</authorinitials>
    <author><firstname>Edward</firstname><surname>Loper</surname></author>
    <authorinitials>edl</authorinitials>
    <title>NLTK Tutorial: Parsing</title>
  </articleinfo>

  <section> <title> Introduction </title>

<para>
In the context of computational modelling, a language is often viewed
as a set of well-formed sentences.  Sequences of words which are not
grammatical are excluded from this set.  Now, since there is no
upper-bound on the length of a sentence, this set is infinite.
For example, it is possible to add an unlimited amount of
material to a sentence by using <literal>and</literal> or by
using relative clauses.
Given the finite resources of a computer, we must devise a finite
description of this infinite set.  We have already encountered this
possibility in the context of regular expressions.  For example, the
expression <literal>a+</literal> describes the set
<literal>{a, aa, aaa, aaaa, ...}</literal>.
</para>

<para>
A well-formed sentence of a language is more than a sequence of words.
Certain groups of words form intermediate structures called phrases
or constituents.
These constituents can be identified using standard syntactic tests,
such as substitution, movement and coordination.  For example, if a
sequence of words can be replaced with a pronoun, then that sequence
is likely to be a constituent.  The following example illustrates this
test:
</para>

<orderedlist><listitem><para>
  <orderedlist>
    <listitem><para><emphasis>Ordinary daily multivitamin and mineral
    supplements</emphasis> could help adults with diabetes fight
    off some minor infections</para></listitem>
    <listitem><para><emphasis>They</emphasis> could help adults with
    diabetes fight off some minor infections</para></listitem>
  </orderedlist>
</para></listitem></orderedlist>

<note><para>
Readers are referred to any introductory text on syntax for fuller
treatment of constituency (e.g. McCawley (1998) The Syntactic
Phenomena of English).
</para></note>

<para>
Paragraph about syntactic trees.
</para>

<para>
A <emphasis>grammar</emphasis> is a formal system which specifies which sequences of
words are well-formed in the language, and which specifies one or more
constituent structures for the sequence.  A <emphasis>parser</emphasis> is a computational
system which processes input sentences according to the rules of the
grammar, and produces one or more constituent structures which conform
to the grammar.  We take a grammar to be a declarative specification
of well-formedness, and a parser to be a procedural interpretation of
the grammar.
In this chapter we will present context-free phrase
structure grammars, and describe some simple parsers that work with them.
</para>

<para>
Parsing has a long and interesting history in computational
linguistics.
[NOTES: the perspective of early generative grammar;
early NLP approaches including ATNs and DCGs;
grammar formalisms and development environments.]
</para>

<para>
Parsing is important in linguistics and natural language processing
for a variety of reasons.  A parser permits a grammar to be evaluated
against a potentially large collection of test sentences, helping the
linguist to identify shortcomings in their analysis.  A parser can be
used as a model of psycholinguistic processing, and used to explain
the processing difficulties that humans have with certain syntactic
constructions (e.g. the so-called "garden path" sentences).  A parser
can serve as the first stage of processing natural language input for
a question-answering system.
</para>

    <warning><para> Some of the material in this tutorial is out of
    date.  We plan to re-write the parsing tutorials in the near
    future.  Until then, see the <ulink
    url="http://nltk.sourceforge.net/ref/nltk.parser.html">reference
    documentation for <literal>nltk.parser</literal></ulink> for more
    up-to-date information. </para></warning>

  </section> <!-- Introduction -->

    <section> <title> Linguistic Overview </title>

<!-- 
X.2 linguistic overview (for non-linguist readers)
    - how have linguists addressed the problem?
    - what are the shortcomings of the non-computational approach?
-->

    <para>
      Context-free phrase structure grammars: the rule formalism
      and its interpretation.
    </para>

    <para>
      Discussion about how CF-PSGs are created by hand.
    </para>

    <para>
      Shortcomings of this approach: unreliable, doesn't scale,
      complex interactions amongst rules makes manual debugging
      almost impossible.  Consequently linguists are unable to
      work with large-coverage grammars.
    </para>

    </section> <!-- Linguistic Overview -->

    <section> <title> Computational Approaches to Parsing </title>

    <para></para>
<!--
X.3 computational model (gentle for linguistics ugrads)
    - what are some good data structures and algorithms?
    - just pick one or two approaches, not encyclopedic
    - NLTK demo - watch the execution of the algorithm
      (screen shots to show execution, side bars to say how
       to do it)
-->

      <section> <title> Top-Down Parsing </title>

        <para></para>

      <section> <title> Bottom-Up Parsing </title>

        <para></para>

      <section> <title> Left-Corner Parsing </title>

        <para></para>

    </section>

    <section> <title> Advanced Topics in Parsing (optional) </title>

    <para></para>

<!--
X.4 advanced topics (optional)
    - other approaches, evaluation, problems
    - challenges for particular languages / language families
    - research questions
-->

    </section>

    <section> <title> Parsing in NLTK </title>

    <para></para>

<!--
X.5 implementation
    - how does NLTK do it?
    - simple problems and worked solutions
    - suggested projects (e.g. for your MSc students)
-->

  <section> <title> Grammars and Lexicons </title>

    <para>A <glossterm>grammar</glossterm> is a formal specification
    for the structure of well-formed
    sentences in some language.  At present, only context-free grammars (CFGs) can be
    represented in NLTK.  A CFG consists of a set of context-free rules.  Context-free
    rules have the form <literal>X -&gt; Y</literal> where <literal>X</literal> is
    a non-terminal, and <literal>Y</literal> is a list of terminals and non-terminals.
    <literal>X</literal> and <literal>Y</literal> are known as the left-hand side and
    right-hand side respectively.
    </para>

    <para>
    In the simplest case, non-terminals and terminals are just Python
    strings.  However, it is possible to use any immutable Python object as a
    non-terminal or terminal.
    </para>

    <para>A grammar can be represented as a tuple of rules, while a lexicon
    can be represented as a tuple of lexical rules.  The only class we need
    to define then is <literal>Rule</literal>.

    </para>

    </section>

    <section> <title> Rules </title>

      <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.html"
      ><literal>nltk.rule</literal></ulink> module defines the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html"
      ><literal>Rule</literal></ulink> class, which is used to represent
      context free rules.  A <literal>Rule</literal> consists of a
      left-hand side and a right-hand side.</para>

      <itemizedlist>
        <listitem><para>The left-hand side is a single non-terminal, which
        may be any Python object.  In the simplest case it is just a string
        (e.g. "NP" or "VP").
        </para></listitem>

        <listitem><para>The right-hand side is a tuple of non-terminals and
        terminals, which may be any Python object.  In the simplest case
        these are strings (e.g. "Det", "the").
        </para></listitem>
      </itemizedlist>

      <para><literal>Rule</literal>s are created with the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html#__init__"
      ><literal>Rule constructor</literal></ulink>, which takes a left-hand side
      and a right-hand side:</para>

<programlisting>
<emphasis># A typical grammar rule S -&gt; NP VP:</emphasis>
&prompt;<command> rule1 = Rule('S', ('NP', 'VP'))</command>
S -> NP VP

<emphasis># A typical lexical rule Det -&gt; 'the':</emphasis>
&prompt;<command> rule2 = Rule('Det', ('the',))</command>
Det -> the
</programlisting>

      <para>A <literal>Rule</literal>'s left-hand side and right-hand
      side are accessed with
      the <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html#lhs"
      ><literal>lhs</literal></ulink>
      and <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html#rhs"
      ><literal>rhs</literal></ulink> methods:
      </para>

<programlisting>
&prompt;<command> rule1.lhs()</command>
'S'

&prompt;<command> rule2.rhs()</command>
('the',)
</programlisting>

      <para> A <literal>Rule</literal>'s right-hand side can also be accessed with
      standard sequence operators: </para>

<programlisting>
&prompt;<command> rule1[0]</command>
'NP'

&prompt;<command> rule2[1]</command>
IndexError: tuple index out of range

&prompt;<command> len(rule1)</command>
2

&prompt;<command> 'the' in rule2</command>
1

&prompt;<command> for cat in rule1: </command>
&prompt2;<command>     print cat</command>
NP
VP
</programlisting>

    </section> <!-- Rules -->

    <section> <title> Building Grammars and Lexicons from Rules </title>

    <para>Grammars and Lexicons can easily be built up from
    <literal>Rule</literal>s as shown in the following examples:</para>

<programlisting>
<emphasis># A simple grammar:</emphasis>
<command>
grammar = (
    Rule('S',('NP','VP')),
    Rule('NP',('Det','N')),
    Rule('NP',('Det','N', 'PP')),
    Rule('VP',('V','NP')),
    Rule('VP',('V','PP')),
    Rule('VP',('V','NP', 'PP')),
    Rule('VP',('V','NP', 'PP', 'PP')),
    Rule('PP',('P','NP'))
)
</command>

<emphasis># A simple lexicon:</emphasis>
<command>
lexicon = (
    Rule('NP',('I',)),
    Rule('Det',('the',)),
    Rule('Det',('a',)),
    Rule('N',('man',)),
    Rule('V',('saw',)),
    Rule('P',('in',)),
    Rule('P',('with',)),
    Rule('N',('park',)),
    Rule('N',('telescope',))
)
</command>
</programlisting>

  </section> <!-- Building Grammars and Lexicons from Rules -->

  <section> <title> Encoding Syntax Trees </title>

    <note>
      <para> The <literal>nltk.tree</literal> module currently has
      only minimal support for representing movement, traces, and
      co-indexing.  We plan to extend the class to support these
      features more fully in the future. </para>
    </note>

    <section> <title> Trees </title>

      <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.tree.html"
      ><literal>nltk.tree</literal></ulink> module defines the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html"
      ><literal>Tree</literal></ulink> class, which is used to
      represent syntax trees.  A <literal>Tree</literal> consists of a
      <glossterm>node value</glossterm>, and one or more
      <glossterm>children</glossterm>. </para>

      <itemizedlist>
        <listitem> <para> The node value is a string containing the
        tree's constituent type (e.g., "NP" or "VP").
        </para></listitem>

        <listitem> <para> The children encode the hierarchical
        contents of the tree.  Each child is either a
        <glossterm>leaf</glossterm> or a
        <glossterm>subtree</glossterm>.</para></listitem>
      </itemizedlist>
    
      <note>
        <para> Although the <literal>Tree</literal> class is usually
        used for encoding syntax trees, it can be used to encode
        <emphasis>any</emphasis> homogenous hierarchical structure
        that spans a text (such as morphological structure or
        discourse structure).  In the general case, leaves and node
        values do not have to be strings. </para>
      </note>

      <para> A <literal>Tree</literal> with node value
      <replaceable>n</replaceable> and children
      <replaceable>c<subscript>1</subscript></replaceable>,
      <replaceable>c<subscript>2</subscript></replaceable>, ...
      <replaceable>c<subscript>n</subscript></replaceable> is written
      <literal>(<replaceable>n</replaceable>:
      <replaceable>c<subscript>1</subscript></replaceable>,
      <replaceable>c<subscript>2</subscript></replaceable>, ...
      <replaceable>c<subscript>n</subscript></replaceable>)</literal>.
      <literal>Tree</literal>s are created with the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html#__init__"
      ><literal>Tree constructor</literal></ulink>, which takes a node
      value and zero or more children: </para>

<programlisting>
    <emphasis># A tree with one child, a leaf:</emphasis>
    &prompt;<command> tree1 = Tree('NP', 'John')</command>
    ('NP': 'John')

    <emphasis># A tree with two children, both of which are leaves:</emphasis>
    &prompt;<command> tree2 = Tree('NP', 'the', 'man')</command>
    ('NP': 'the' 'man')

    <emphasis># A tree with two children, one leaf and one subtree:</emphasis>
    &prompt;<command> tree3 = Tree('VP', 'saw', tree2)</command>
    ('VP': 'saw' ('NP': 'the' 'man'))
</programlisting>

      <para> A <literal>Tree</literal>'s node value is accessed with
      the <ulink url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html#node"
      ><literal>node</literal></ulink> method: </para>

<programlisting>
    &prompt;<command> tree1.node()</command>
    'NP'
</programlisting>

      <para> A <literal>Tree</literal>'s children are accessed with
      standard sequence operators: </para>

<programlisting>
    &prompt;<command> tree3[0]</command>
    'saw'
    &prompt;<command> tree3[1]</command>
    ('NP': 'the' 'man')
    &prompt;<command> len(tree3)</command>
    2
    &prompt;<command> 'saw' in tree3</command>
    1
    &prompt;<command> for child in tree3: </command>
    &prompt2;<command>     print child</command>
    saw 
    ('NP': 'the' 'man')
    &prompt;<command> [child.upper() for child in tree2] </command>
    ['THE', 'MAN']
    &prompt;<command> tree3[:] </command>
    ('saw', ('NP': 'the' 'man'))
</programlisting>

      <para> The printed representation for complex
      <literal>Tree</literal>s can be difficult to read.  In these
      cases, the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html#draw"
      ><literal>draw</literal></ulink> method can be very useful.  This
      method opens a new window, containing a graphical representation
      of the tree.  </para>

<programlisting>
    &prompt;<command> tree3.draw()</command>
</programlisting>

      <para> The tree display window allows you to zoom in and out; to
      collapse and expand subtrees; and to print the graphical
      representation to a postscript file. </para>

      <para> The <literal>Tree</literal> class implements a number of
      other useful methods.  See the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html"
      ><literal>Tree</literal> reference documentation</ulink> for more
      information about these methods. </para>

<programlisting>
    &prompt;<command> tree3.leaves()</command>
    ('saw', 'the', 'man')
    &prompt;<command> tree3.height()</command>
    3
    &prompt;<command> tree3.nodes()</command>
    ('VP': ('NP':))
</programlisting>

    </section> <!-- Trees -->

    <section> <title> Tree Tokens </title>

      <para> NLTK makes a distinction between <glossterm>tree
      type</glossterm>s and <glossterm>tree token</glossterm>s, that
      is analogous to the distinction between word types and word
      tokens.  In particular, a tree token is an individual occurance
      of a tree type in a text; and a tree type is an abstract syntax
      tree, without context. </para>

      <para> Tree tokens are represented with the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.TreeToken.html"
      ><literal>TreeToken</literal></ulink> class.
      <literal>TreeToken</literal>s behave very much like
      <literal>Tree</literal>s, except that the leaves of a
      <literal>TreeToken</literal> are word tokens, not word types.  
      </para>

    </section> <!-- TreeTokens -->

  </section> <!-- Encoding Syntax Trees -->

  <section> <title> The Parser Interface </title>

    <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.html"
    ><literal>parser</literal></ulink> module defines the
    <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.ParserI.html"
    ><literal>ParserI</literal></ulink> class, which is the standard interface
    which all parsers should support.  This class should only be used in the
    definition of other parser classes, which should inherit from the
    <literal>ParserI</literal> class.</para>

    <para>The <literal>ParserI</literal> class defines
    <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.ParserI.html#parse"
    ><literal>parse</literal></ulink>, which takes a list of tokens as its argument
    and returns a list of <literal>TreeToken</literal>s.
    The <literal>parse</literal> function has an optional second argument
    which specifies the maximum number of parses to return.  No program should
    call the <literal>ParserI.parse</literal> method.  Derived classes must
    implement their own <literal>parse</literal> method.</para>

    <para>A parser returns an empty list of trees in the situation where it was
    unable to assign a tree to the list of tokens.  This happens in situations
    where the list of tokens forms an ungrammatical sentence, or when the grammar
    is deficient, or when the search strategy of the parser does not explore the
    section of the search space where the parse tree(s) are found.</para>

    <para>A parser returns
    more than one tree in the case of syntactic ambiguity.  The sentence being
    parsed may be genuinly ambiguous, or the grammar may be deficient.  Statistical
    parsers usually return the most likely parse (based on training data), or the
    set of <replaceable>n</replaceable> most likely parses.  The same interface
    applies to these cases.  (Where the probability of the parse tree needs to
    be returned, we assume this is stored in the root node of the tree.)  When
    asked to return <replaceable>n</replaceable> parses, we assume such a parser
    will rank parses in order of decreasing likelihood, and return the
    <replaceable>n</replaceable>-best parses.</para>

    <para>Parsers may be used anywhere where there is need for processing
    sequences with a grammar.  In the most common case, the sequence consists
    of a string of words forming a sentence.  However, other cases are possible,
    e.g. the string of characters forming a syllable, the string of morphemes
    forming a word, the string of sentences forming a text.  We could also have
    grammars over subsequences.  For example, the collection of XML elements in
    a document forms a subsequence of the document, and we could specify a grammar
    over those elements alone, ignoring document content.</para>

    <para>The <literal>ParserI</literal> class also defines a
    <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.ParserI.html#parse"
    ><literal>parse_types</literal></ulink> method, which takes a list of token types
    (e.g. strings) and returns a list of <literal>Tree</literal>s.  This is
    useful in the case where the sentence to be parsed did not come from a
    tokenized text.  This method works by converting the list of types into
    a list of tokens, then calling <literal>parse</literal> as before.</para>

  </section> <!-- The Parser Interface -->

  <section> <title> Simple Parsers </title>

    <para>Simple top-down and bottom-up parsers can easily be defined
    using classes which inherit from <literal>ParserI</literal>.
    Here is some pseudocode to use as the basis of two simple modules.
    Writing these modules is left as an exercise for the reader.
    More work is required in order to return trees.</para>

<programlisting>
# elementary top-down parser
def tdparse(goal, sent): 
    if goal == sent == empty:
        pass # we're finished
    else:
        if goal[0] == sent[0]:
	    tdparse(goal[1:], sent[1:])
        else:
            for rule in grammar:
                if rule.lhs() == goal[0]:
                    make a local copy of the goal list
                    goal[:1] = rule.rhs()
                    tdparse(goal, sent)

# left-corner parser
def lcparse(goal, sent):
    # this is like tdparse, except the step which iterates over the rules
    # of the grammar only considers rules whose "left corner" matches the next
    # word of the input stream.  The left corner of a lexical rule is the
    # content of the rule.  The left corner of a non-lexical rule R is the left
    # corner of R[0], the first element on the RHS of the rule.

# elementary bottom-up parser
def buparse(sent):
    if sent == [S]:
        pass # we're finished
    else:
        for rule in grammar:
	    does rule.rhs() match any sublist of sent?
            if so, replace the substring with the LHS of the rule
            buparse(sent)
</programlisting>

    <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.srparser_template.html"
    ><literal>srparser_template</literal></ulink> module defines the
    <ulink url="http://nltk.sourceforge.net/ref/nltk.srparser_template.SRParser.html"
    ><literal>SRParser</literal></ulink> class, which is a template for a
    shift-reduce parser.</para>

  </section> <!-- The Parser Interface -->

  </section> <!-- Parsing in NLTK -->

</article>
