<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.1//EN" [
<!ENTITY prompt "<prompt>&gt;</prompt><prompt>&gt;</prompt><prompt>&gt;</prompt>">
<!ENTITY prompt2 "<prompt>...</prompt>">
<!ENTITY refdoc "http://nltk.sourceforge.net/ref">
]>

<article>
  <articleinfo>
    <author><firstname>Steven</firstname><surname>Bird</surname></author>
    <authorinitials>sb</authorinitials>
    <author><firstname>Edward</firstname><surname>Loper</surname></author>
    <authorinitials>edl</authorinitials>
    <title>NLTK Tutorial: Chunking</title>
  </articleinfo>

  <section> <title> Introduction </title>

    <para> For many practical purposes it is not necessary to
    construct a complete parse tree for a sentence.  <glossterm>Chunk
    parsing</glossterm>, also known as <glossterm>partial
    parsing</glossterm>, <glossterm>light parsing</glossterm>, or just
    <glossterm>chunking</glossterm>, is an approach in which the
    parser assigns incomplete syntactic structure to the phrase.  The
    most common use of chunking is in <glossterm>information
    extraction</glossterm> and <glossterm>message
    understanding</glossterm>, where the content of a text is mined
    for information that will be used to fill out a template.  Chunk
    parsing is actually more like tagging than conventional parsing,
    in the sense that it typically uses finite-state methods and
    employs rules that work directly off the (tagged) surface string.
    This contrasts with conventional parsing, which normally uses
    context-free rules expressed over abstract categories
    (e.g. phrasal categories).</para>

    <para> In terms of the other NLP tasks, chunking usually takes
    place after tokenization and tagging.</para>

    <para> Typically, chunk parsers are based on finite-state methods.
    The constraints about well-formed chunks are expressed using
    regular expressions over the sequence of word tags.
    This tutorial describes the NLTK regular-expression chunk parser.
    </para>

  </section> <!-- Introduction -->

  <section> <title> The Chunk Parser Interface </title>

    <para> Unlike conventional parsers, chunk parsers do not need to
    construct complete parse trees.  Instead, they return a simple
    structure known as a chunk structure.  A <glossterm>chunk
    structure</glossterm> is a list, containing a mixture of tokens
    and sublists of tokens.  Here is an example of a chunk
    structure: </para>

<screen>
[
  [
    'the'/'DT'@[1],
    'cat'/'NN'@[2]
  ],
  'sat'/'VBD'@[3],
  'on'/'IN'@[4],
  [
    'the'/'DT'@[5],
    'mat'/'NN'@[6]
  ]
]
</screen>

    <para> Before we give a more precise definition of chunk parsing,
    we will define some "abstract types," or names for data
    structures: </para>

    <informaltable>
      <tgroup cols="3">
        <tbody>
          <row>
            <entry><glossterm>tagged token</glossterm></entry>
            <entry>:=</entry>
            <entry>a <literal>Token</literal> whose type is 
                   a <literal>TaggedType</literal></entry>
          </row>
          <row>
            <entry><glossterm>tagged text</glossterm></entry>
            <entry>:=</entry>
            <entry>list of <emphasis>tagged tokens</emphasis></entry>
          </row>
          <row>
            <entry><glossterm>chunk</glossterm></entry>
            <entry>:=</entry>
            <entry>list of <emphasis>tagged tokens</emphasis></entry>
          </row>
          <row>
            <entry><glossterm>chunk structure</glossterm></entry>
            <entry>:=</entry>
            <entry>list of (<emphasis>tagged token</emphasis> or 
                   <emphasis>chunk</emphasis>)</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <note>
      <para> Although the terms <emphasis>tagged text</emphasis> and
      <emphasis>chunk</emphasis> have the same definition, they are
      used in different contexts. </para>
    </note>

    <para> Chunk parsers are defined by the 
    <ulink url="&refdoc;/nltk.chunkparser.ChunkParserI.html"
    ><literal>ChunkParserI</literal></ulink> interface.  Every chunk
    parser must define a 
    <ulink url="&refdoc;/nltk.chunkparser.ChunkParserI.html#parse"
    ><literal>parse</literal></ulink> method.  This method identifies
    the chunks in a tagged text, by returning a chunk structure that
    corresponds to the text. </para>

    <note><para>The current definition of chunk structure is too weak
    to express a more general kind of chunking which associates a type
    with each chunk.  For example, there are chunkers which can
    identify both NP and VP chunks.  For these it is necessary to
    define a more expressive representation.  For this and other
    reasons, we may eventually change the
    <literal>ChunkParserI</literal> to use the
    
    <ulink url="&refdoc;/nltk.tree.TreeToken.html"
    ><literal>TreeToken</literal></ulink> class instead of chunk
    structures.</para>
    </note>

    <para>All chunk parsers, including the
    <literal>REChunkParser</literal> class discussed below, should
    inherit from <literal>ChunkParserI</literal>, and reimplement its
    <literal>parse</literal> method. </para>

  </section> <!-- The Chunk Parser Interface -->

  <section> <title> The Chunking Tokenizer </title>

    <para>A common file representation for chunked tagged text is as
    follows:</para>

<screen>
[ the/DT little/JJ cat/NN ] 
sat/VBD on/IN 
[ the/DT mat/NN ]
</screen>

    <para>It is often useful to be able to tokenize
    text input in this format as part of the evaluation process.
    For this purpose, the 
    <ulink url="&refdoc;/nltk.chunkparser.html"
    ><literal>nltk.chunkparser</literal></ulink>
    module contains a special kind of tagged tokenizer class, the
    <ulink url="&refdoc;/nltk.tagger.ChunkedTaggedTokenizer.html"
    ><literal>ChunkTaggedTokenizer</literal></ulink>.</para>

<programlisting>
    &prompt; <command>from nltk.chunkparser import ChunkedTaggedTokenizer</command>
    &prompt; <command>correct_sent = """
    [ the/DT little/JJ cat/NN ]
    sat/VBD on/IN
    [ the/DT mat/NN ]
    """</command>
    &prompt; <command>tokenizer = ChunkedTaggedTokenizer()</command>
    &prompt; <command>correct_chunks = tokenizer.tokenize(correct_sent)</command>
    [['the'/'DT'@[0w], 'little'/'JJ'@[1w], 'cat'/'NN'@[2w]],
     'sat'/'VBD'@[3w], 'on'/'IN'@[4w], 
     ['the'/'DT'@[5w], 'mat'/'NN'@[6w]]]
</programlisting>
    
    <section> <title> Un-Chunking </title>

      <para>Another utility defined in the
      <literal>nltk.chunkparser</literal> module, 
      <ulink url="&refdoc;/nltk.chunkparser.html#unchunk"
      ><literal>unchunk</literal></ulink>, will convert a chunk
      structure to a chunked text by removing all chunking: </para>

<programlisting>
    &prompt; <command>unchunked_sent = unchunk(correct_chunks)</command>
    ['the'/'DT'@[0w], 'little'/'JJ'@[1w], 'cat'/'NN'@[2w], 'sat'/'VBD'@[3w],
     'on'/'IN'@[4w], 'the'/'DT'@[5w], 'mat'/'NN'@[6w]]
</programlisting>

    </section> <!-- Unchunk -->

    <section> <title> LineTokenizer </title>
      <para> The <literal>ChunkTaggedTokenizer</literal> is often
      used in conjunction with the 
      <ulink url="&refdoc;/nltk.token.html#LineTokenizer"
      ><literal>LineTokenizer</literal></ulink> class, which reads a
      file that contains one sentence per line.  For example, the
      following example reads a file containing chunked tagged
      sentences, one per line: </para>

<programlisting>
    &prompt; <command>text = open('corpus.txt').read()</command>
    &prompt; <command>sentences = LineTokenizer.tokenize(text)</command>
    &prompt; <command>ctt = ChunkedTaggedTokenizer()</command>
    &prompt; <command>for sentence in sentences:</command>
    &prompt2;     <command>chunked_sent = ctt.tokenize(sentence, source=sentence.loc())</command>
    &prompt2;     <command>print chunked_sent</command>
</programlisting>

    </section> <!-- LineTokenizer -->

  </section> <!-- The Chunking Tokenizer -->

  <section> <title> REChunkParser </title>

    <para> For the remainder of this tutorial, we will examine 
    
    <ulink url="&refdoc;/nltk.rechunkparser.REChunkParser.html"
    ><literal>REChunkParser</literal></ulink>.  This chunk parser uses
    a sequence of regular expression based
    <glossterm>rules</glossterm> to chunk a tagged text. </para>

    <para> <literal>REChunkParser</literal> works by manipluating a
    <glossterm>chunking hypothesis</glossterm>, which records a
    particular chunking of the text.  The
    <literal>REChunkParser</literal> begins with a chunking hypothesis
    where no tokens are chunked.  Each rule is then applied, in turn,
    to the chunking hypothesis.  After the all of the rules have been
    applied, the chunk structure corresponding to the final chunking
    hypothesis is returned. </para>

    <para> New <literal>REChunkParser</literal>s are constructed from
    a list of rules, using the 
    <ulink url="&refdoc;/nltk.rechunkparser.REChunkParser.html#__init__"
    ><literal>REChunkParser</literal> constructor</ulink>:</para>

<programlisting>
    &prompt; <command>rules = [rule1, rule2, rule3] </command>
    &prompt; <command>chunkparser = REChunkParser(rules)</command>
</programlisting>

    <note> 
      <para> We will discuss how to construct rules in the following
      sections. </para>
    </note>

    <para> Tagged texts are chunked using the 
    <ulink url="&refdoc;/nltk.rechunkparser.REChunkParser.html#parse"
    ><literal>parse</literal></ulink> method:</para>

<programlisting>
    &prompt; <command>chunkparser.parse(unchunked_sent)</command>
    [['the'/'DT'@[0w], 'little'/'JJ'@[1w], 'cat'/'NN'@[2w]], 
     'sat'/'VBD'@[3w], 'on'/'IN'@[4w], 
     ['the'/'DT'@[5w], 'mat'/'NN'@[6w]]]
</programlisting>

  </section> <!-- REChunkParser intro -->

  <section> <title> Tag Strings and Tag Patterns </title>

    <para> Rules are defined in terms of regular expression patterns
    over "tag strings."  A <glossterm>tag string</glossterm> is a
    string consisting of angle-braket delimited tag names.  An example
    of a <glossterm>tag string</glossterm> is: </para>

<screen>
    &lt;DT&gt;&lt;JJ&gt;&lt;NN&gt;&lt;VBD&gt;&lt;DT&gt;&lt;NN&gt;
</screen>
      
    <note>
      <para> Tag strings do not contain any whitespace. </para>
    </note>

    <para> Most rules are defined using a special kind of regular
    expression pattern, called a <glossterm>tag pattern</glossterm>.
    Tag patterns are identical to <literal>re</literal> regular
    expression patterns in most respects; however, there are a few
    differences, which are intended to simplify their use with
    <literal>REChunkParser</literal>s:</para>

    <itemizedlist>
      <listitem>
        <para> In tag patterns, "&lt;" and "&gt;" act as if they are
        surrounded by parenthases; so the tag pattern
        "<literal>&lt;NN&gt;+</literal>" matches one or more repetitions of
        "<literal>&lt;NN&gt;</literal>"; and "<literal>&lt;NN|JJ&gt;</literal>"
        matches "<literal>&lt;NN&gt;</literal>" or
        "<literal>&lt;JJ&gt;</literal>."</para>
      </listitem>
      <listitem>
        <para> Whitespace in tag patterns is ignored; so
        "<literal>&lt;DT&gt; | &lt;NN&gt;</literal>" is equivalant to
        "<literal>&lt;DT&gt;|&lt;NN&gt;</literal>".  This allows you to make your
        tag patterns easier to read, by inserting whitespace in
        appropriate places. </para>
      </listitem>
      <listitem>
        <para>In tag patterns, "<literal>.</literal>" is equivalant to
        "<literal>[^{}&lt;&gt;]</literal>"; so "<literal>&lt;NN.*&gt;</literal>"
        matches any single tag starting with
        "<literal>NN</literal>."</para>
      </listitem>
    </itemizedlist>
        
  </section> <!-- Tag Strings & Tag Patterns -->

  <section> <title> REChunkParser Rules </title>

    <para> <literal>REChunkParser</literal> rules are all defined in
    terms of regular expression patterns over tag strings.
    <literal>nltk.rechunkparser</literal> currently defines six
    different kinds of rule.  
    <ulink url="&refdoc;/nltk.rechunkparser.REChunkParserRule.html"
    ><literal>REChunkParserRule</literal></ulink> is the most general
    kind of rule; all other rules are derived from it.  We will cover
    <literal>REChunkParserRule</literal> itself later in this
    tutorial.  First, we will cover the simpler rules that are derived
    from <literal>REChunkParserRule</literal>: </para>

    <itemizedlist>
      <listitem>
        <para>
        <ulink url="&refdoc;/nltk.rechunkparser.ChunkRule.html"
        ><literal>ChunkRule</literal></ulink> chunks anything that
        matches a given tag pattern.</para>
      </listitem>
      <listitem>
        <para>
        <ulink url="&refdoc;/nltk.rechunkparser.ChinkRule.html"
        ><literal>ChinkRule</literal></ulink> chinks anything that
        matches a given tag pattern.</para>
      </listitem>
      <listitem>
        <para>
        <ulink url="&refdoc;/nltk.rechunkparser.UnChunkRule.html"
        ><literal>UnChunkRule</literal></ulink> will un-chunk any chunk
        that matches a given tag pattern.</para>
      </listitem>
      <listitem>
        <para>
        <ulink url="&refdoc;/nltk.rechunkparser.MergeRule.html"
        ><literal>MergeRule</literal></ulink> can be used to merge two
        contiguous chunks.</para>
      </listitem>
      <listitem>
        <para>
        <ulink url="&refdoc;/nltk.rechunkparser.SplitRule.html"
        ><literal>SplitRule</literal></ulink> can be used to split a
        single chunk into two smaller chunks.</para>
      </listitem>
    </itemizedlist>

    <section> <title> Rule Descriptions </title>

      <para> Each rule must have a "description" associated with it,
      which provides a short explanation of the purpose or the effect
      of the rule.  This description is accessed via the 
      <ulink url="&refdoc;/nltk.rechunkparser.REChunkParserRule.html#descr"
      ><literal>descr</literal></ulink> method: </para>

<programlisting>
    &prompt; <command>print rule1.descr()</command>
    'Chunk sequences of NN and DT'
</programlisting>

    </section> <!-- Descriptions -->

  </section> <!-- Rules: intro -->

  <section> <title> ChunkRule </title>

    <para> The simplest type of rule is 
    <ulink url="&refdoc;/nltk.rechunkparser.ChunkRule.html"
    ><literal>ChunkRule</literal></ulink>.  A
    <literal>ChunkRule</literal> chunks anything that matches a given
    tag pattern.  <literal>ChunkRule</literal>s are created with the
    
    <ulink url="&refdoc;/nltk.rechunkparser.ChunkRule.html#__init__"
    ><literal>ChunkRule</literal> constructor</ulink>, which takes a
    tag pattern and a description string.  For example, the following
    code creates and uses an <literal>REChunkParser</literal> that
    chunks any sequence of tokens whose tags are all
    "<literal>NN</literal>" or "<literal>DT</literal>": </para>

<programlisting>
    &prompt; <command>rule1 = ChunkRule('&lt;NN|DT&gt;+',
                          'Chunk sequences of NN and DT')</command>
    &prompt; <command>chunkparser = REChunkParser( [rule1] )</command>
    &prompt; <command>chunkparser.parse(unchunked_sent)</command>
    [['the'/'DT'@[0w]], 
     'little'/'JJ'@[1w], 
     ['cat'/'NN'@[2w]], 
     'sat'/'VBD'@[3w], 'on'/'IN'@[4w], 
     ['the'/'DT'@[5w], 'mat'/'NN'@[6w]]]
</programlisting>

    <para> We can also use more complex tag patterns.  The following
    code chunks any sequence of tokens beginning with an optional
    determiner ("<literal>DT</literal>"), followed by zero or more
    adverbs of any type ("<literal>JJ.*</literal>"), followed by a
    single noun of any type ("<literal>NN.*</literal>"). </para>

<programlisting>
    &prompt; <command>rule1 = ChunkRule('&lt;DT&gt;?&lt;JJ.*&gt;*&lt;NN.*&gt;',
                    'Chunk optional det, zero or more adj, and a noun')</command>
    &prompt; <command>chunkparser = REChunkParser([rule1])</command>
    &prompt; <command>chunkparser.parse(unchunked_sent)</command>
    [['the'/'DT'@[0w], 'little'/'JJ'@[1w], 'cat'/'NN'@[2w]], 
     'sat'/'VBD'@[3w], 'on'/'IN'@[4w], 
     ['the'/'DT'@[5w], 'mat'/'NN'@[6w]]]
</programlisting>

    <para> If a tag pattern matches at multiple overlapping locations,
    the first match takes precedence.  For example, if we apply a rule
    that matches two consecutive nouns to a text containing three
    consecutive nouns, then the first two nouns will be chunked: </para>

<programlisting>
    &prompt; <command>noun_str = "dog/NN cat/NN mouse/NN"</command>
    'dog/NN cat/NN mouse/NN'
    &prompt; <command>three_nouns = TaggedTokenizer().tokenize(noun_str)</command>
    ['dog'/'NN'@[0w], 'cat'/'NN'@[1w], 'mouse'/'NN'@[2w]]
    &prompt; <command>rule1 = ChunkRule('&lt;NN&gt;&lt;NN&gt;',
                    'Chunk two consecutive nouns')</command>
    &prompt; <command>chunkparser = REChunkParser([rule1])</command>
    &prompt; <command>chunkparser.parse(three_nouns)</command>
    [['dog'/'NN'@[0w], 'cat'/'NN'@[1w]], 
     'mouse'/'NN'@[2w]]
</programlisting>

    <section> <title> Tracing Parsing </title>

      <para> The <literal>parse</literal> method of
      <literal>REChunkParser</literal> takes an optional
      "<literal>trace</literal>" argument, which specifies whether
      debugging output should be shown during parsing.  This output
      shows the rules that are applied, and shows the chunking
      hypothesis at each stage of processing.  </para>

<programlisting>
    &prompt; <command>chunkparser = REChunkParser([rule1], 1)</command>
    &prompt; <command>chunkparser.parse(unchunked_sent, 1)</command>
    Input:
                    &lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;  &lt;VBD&gt;  &lt;IN&gt;  &lt;DT&gt;  &lt;NN&gt; 
    Chunk optional det, zero or more adj, and a noun:
                   {&lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;} &lt;VBD&gt;  &lt;IN&gt; {&lt;DT&gt;  &lt;NN&gt;}

    [['the'/'DT'@[0w], 'little'/'JJ'@[1w], 'cat'/'NN'@[2w]], 
     'sat'/'VBD'@[3w], 'on'/'IN'@[4w], 
     ['the'/'DT'@[5w], 'mat'/'NN'@[6w]]]
</programlisting>

    </section> <!-- Tracing -->

    <section> <title> Cascading Rules </title>

      <para> <literal>REChunkParser</literal>s can be generated from
      multiple <literal>ChunkRule</literal>s.  In this case, each rule
      will be applied in turn.  For example, the following code chunks
      the example sentence by first finding all sequences of three
      tokens whose tags are "<literal>DT</literal>",
      "<literal>JJ</literal>", and "<literal>NN</literal>"; and then
      looking for any sequence of tokens whose tags are either
      "<literal>DT</literal>" or "<literal>NN</literal>".  </para>

<programlisting>
    &prompt; <command>rule1 = ChunkRule('&lt;DT&gt;&lt;JJ&gt;&lt;NN&gt;',
                          'Chunk det+adj+noun')</command>
    &prompt; <command>rule2 = ChunkRule('&lt;DT|NN&gt;+',
                          'Chunk sequences of NN and DT')</command>
    &prompt; <command>chunkparser = REChunkParser( [rule1, rule2] )</command>

    <emphasis># Parse unchunked_sent with tracing turned on.</emphasis>
    &prompt; <command>chunkparser.parse(unchunked_sent, 1)</command>
    Input:
                    &lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;  &lt;VBD&gt;  &lt;IN&gt;  &lt;DT&gt;  &lt;NN&gt; 
    Chunk det+adj+noun:
                   {&lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;} &lt;VBD&gt;  &lt;IN&gt;  &lt;DT&gt;  &lt;NN&gt; 
    Chunk sequences of NN and DT:
                   {&lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;} &lt;VBD&gt;  &lt;IN&gt; {&lt;DT&gt;  &lt;NN&gt;}

    [['the'/'DT'@[0w], 'little'/'JJ'@[1w], 'cat'/'NN'@[2w]], 
     'sat'/'VBD'@[3w], 'on'/'IN'@[4w], 
     ['the'/'DT'@[5w], 'mat'/'NN'@[6w]]]
</programlisting>

      <para> When a <literal>ChunkRule</literal> is applied to a
      chunking hypothesis, it will only create chunks that do not
      partially overlap with chunks already in the hypothesis.  Thus,
      if we apply these two rules in reverse order, we will get a
      different result: </para>

<programlisting>
    &prompt; <command>chunkparser = REChunkParser( [rule2, rule1] )</command>

    <emphasis># Parse unchunked_sent with tracing turned on.</emphasis>
    &prompt; <command>chunkparser.parse(unchunked_sent, 1)</command>
    Input:
                    &lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;  &lt;VBD&gt;  &lt;IN&gt;  &lt;DT&gt;  &lt;NN&gt; 
    Chunk sequences of NN and DT:
                   {&lt;DT&gt;} &lt;JJ&gt; {&lt;NN&gt;} &lt;VBD&gt;  &lt;IN&gt; {&lt;DT&gt;  &lt;NN&gt;}
    Chunk: Det+adj+noun:
                   {&lt;DT&gt;} &lt;JJ&gt; {&lt;NN&gt;} &lt;VBD&gt;  &lt;IN&gt; {&lt;DT&gt;  &lt;NN&gt;}

    [['the'/'DT'@[0w], 'little'/'JJ'@[1w], 'cat'/'NN'@[2w]], 
     'sat'/'VBD'@[3w], 'on'/'IN'@[4w], 
     ['the'/'DT'@[5w], 'mat'/'NN'@[6w]]]
</programlisting>

      <para> Here, rule 2 did not find any chunks, since all chunks
      that matched its tag pattern overlapped with chunks that were
      already in the hypothesis. </para>

    </section> <!-- Cascading Rules -->

    
    

    <!--
    A rule specifying how to add chunks to a C{ChunkString}, using a
    matching tag pattern.  When applied to a C{ChunkString}, it will
    find any substring that matches this tag pattern and that is not
    already part of a chunk, and create a new chunk containing that
    substring.
    -->

  </section> <!-- ChunkRule -->

  



<!-- ==================================================== -->
<!-- ==================================================== -->
<!-- ==================================================== -->


  <section> <title> OLD STUFF: Process Me! </title>


  <section> <title> The String Representation of Tokenized Sequences </title>

    <para>Before we can apply a regular expression to a sequence of objects,
    those objects must first be encoded in a string.  This presents a difficulty.
    We want to apply the chunker to the output of the tagger, and we want the
    output of the chunker simply add the chunking information.  However, on
    the face of it, we must first project out the tags into a string, chunk
    the string, then somehow get back to the non-string representation.  The
    following sequence of Python objects illustrate the dilemma:</para>

<programlisting>
<emphasis># tagger output</emphasis>
[ 'the'/'DT'@[1], 'cat'/'NN'@[2] 'sat'/'VBD'@[3], 'on'/'IN'@[4],
'the'/'DT'@[5], 'mat'/'NN'@[6] ]

<emphasis># the list of tags</emphasis>
[ 'DT', 'NN', 'VBD', 'IN', 'DT', 'NN' ]

<emphasis># the string of tags ready for chunking</emphasis>
'DT NN VBD IN DT NN'

<emphasis># the chunked tags</emphasis>
'[DT NN] VBD IN [DT NN]'

<emphasis># some black magic?</emphasis>
[ [ 'the'/'DT'@[1], 'cat'/'NN'@[2] ], 'sat'/'VBD'@[3], 'on'/'IN'@[4],
[ 'the'/'DT'@[5],'mat'/'NN'@[6] ] ]
</programlisting>

    <para>The solution is to encode each token in a string which contains sufficient
    information for the token to be reconstructed, and then write chunking rules
    which only consider the tags, ignoring the types and the locations.
    The <literal>REChunkParser</literal> class provides a convenient interface
    hides this additional layer of complexity from the developer.</para>

    <para>The string representation of a token is illustrated below:</para>

<programlisting>
<emphasis># a token</emphasis>
'the'/'DT'@[1]

<emphasis># the string encoding</emphasis>
'&gt;the/DT@[1]&lt;'
</programlisting>

    <para>The <literal>rechunkparser</literal> module provides a function
    <literal>tag2str</literal> which takes a list of tagged tokens and converts
    it into a string, concatenating the string encoding of each token.</para>

    <note><para>Note that no spaces are inserted between the encoded tokens.
    In the encoding, tokens are delimited with &lt; and &gt;, not with
    whitespace.</para></note>

<programlisting>
&prompt; <command>ttokens = [ 'the'/'DT'@[1], 'cat'/'NN'@[2] 'sat'/'VBD'@[3],
'on'/'IN'@[4], 'the'/'DT'@[5], 'mat'/'NN'@[6] ]</command>
&prompt; <command>tag2str(ttokens)</command>
'&lt;the/DT@[1]&gt;&lt;cat/NN@[2]&gt;&lt;sat/VBD@[3]&gt;&lt;on/IN@[4]&gt;&lt;the/DT@[5]&gt;&lt;mat/NN@[6]&gt;'
</programlisting>

    <para>The chunker operates on this string, not by splitting it, but
    by inserting/removing chunk delimiters.  The <literal>rechunkparser</literal>
    module uses braces as delimiters since, unlike parentheses and square brackets, these
    do not usually need to be backslash-escaped in regular expressions.
    Thus, the chunked representation of the above example is as follows:
    </para>

<programlisting>
'{&lt;the/DT@[1]&gt;&lt;cat/NN@[2]&gt;}&lt;sat/VBD@[3]&gt;&lt;on/IN@[4]&gt;{&lt;the/DT@[5]&gt;&lt;mat/NN@[6]&gt;}'
</programlisting>

    <para>The module provides a method called <literal>str2chunks</literal>
    which builds a chunk structure from this string.  This is what is
    returned by the chunkparser for further processing, e.g. by an
    information extraction system.</para>

    <para>It is possible to build an NLTK chunker based solely on the
    infrastructure provided above.  However, we also provide classes to
    make it easier to express chunk rules and chunk parsers.  The
    rest of the section discusses these.</para>

    </section> <!-- The String Representation of Tokenized Sequences -->

    <section> <title> Chunk Rules and Abstract Chunk Rules </title>

    <para>Chunk rules operate on strings of encoded tokens to insert
    and delete the chunk delimiters.  For instance, a rule might
    create a chunk by inserting <literal>{</literal> before the fifth
    token, and inserting <literal>}</literal> after the sixth token.
    Equally, a rule could combine two adjacent chunks by
    <emphasis>removing</emphasis> <literal>}{</literal> from the string.</para>

    <para>The
    <ulink url="&refdoc;/nltk.rechunkparser.ChunkRule.html"
    ><literal>ChunkRule</literal></ulink> class provides a convenient wrapper
    for Python's built-in <literal>re</literal> (regular expression) class.
    The <literal>ChunkRule</literal> constructor takes five arguments:</para>

    <itemizedlist>
      <listitem><para><emphasis>target</emphasis>
        The material that the regular expression must apply to
      </para></listitem>
      <listitem><para><emphasis>action</emphasis>
        The action performed on this material
        (i.e. reproducing the material using the <literal>\1</literal>
        construct and adding or removing braces).
      </para></listitem>
      <listitem><para><emphasis>left</emphasis>
        The left-hand context in which this rule applies.
      </para></listitem>
      <listitem><para><emphasis>right</emphasis>
        The right-hand context in which this rule applies.
      </para></listitem>
      <listitem><para><emphasis>doc</emphasis>
        Brief documentation of the function of the rule
        (e.g. <literal>'chunking groups of JJ|NN'</literal>).
      </para></listitem>
    </itemizedlist>

    <para>Both <literal>target</literal> and <literal>action</literal>
    are explicit arguments.  The remaining arguments are optional,
    keyword arguments.  Here is a chunk rule which inserts the chunk
    delimiters around any tag <literal>NN</literal>.</para>

<programlisting>
ChunkRule(r'(&lt;[^&gt;]*/NN@[^&gt;]*&gt;)', r'{\1}', doc='chunk NNs')
</programlisting>

    <note><para>Note that we use Python's raw string notation, so that
    the interpreter does not preprocess the backslash escapes.  In general,
    it is a good idea to use the raw string notation whenever regular
    expressions are involved.  We follow this practice here.</para></note>

    <para>This rule matches tokens like
    <literal>&lt;cat/NN@[1]&gt;</literal>,
    and flags them as chunks by wrapping them with the chunk
    delimiters.  This is probably the simplest kind of chunk rule,
    and it is already incomprehensible.  Therefore, the
    <literal>rechunkparser</literal> module defines a more
    convenient interface, namely the <literal>AbstractChunkRule</literal>
    class.</para>

    <para>The
    <ulink url="&refdoc;/nltk.rechunkparser.AbstractChunkRule.html"
    ><literal>AbstractChunkRule</literal></ulink>
    class is a simple wrapper for the <literal>ChunkRule</literal> class.
    <literal>AbstractChunkRule</literal> is a derived class whose
    initializer preprocesses its <literal>target</literal>,
    <literal>left</literal> and <literal>right</literal> arguments.
    The calling function can now employ regular expressions
    <emphasis>over the tags only</emphasis>,
    ignoring the fact that the string also contains types and
    locations.  The chunk rule we saw above can now be written
    as follows:</para>

<programlisting>
AbstractChunkRule(r'(&lt;NN&gt;)', r'{\1}', doc='chunk NNs')
</programlisting>

    <para>Given this simpler format it is now relatively straightforward
    to construct some quite complex chunk rules.  The first generalization
    is to note that the tags themselves have some internal structure that
    we can exploit.  For example, a plural noun is tagged <literal>NNS</literal>.
    Suppose we wished to treat all tags starting with <literal>NN</literal>
    in a single chunk rule.  We could do this as follows:</para>

<programlisting>
AbstractChunkRule(r'(&lt;NN.*&gt;)', r'{\1}', doc='chunk NNX')
</programlisting>

    <para>In some cases, there is no common prefix and so we are forced
    to use disjunction.  Here is a chunk rule which puts chunk delimiters
    around any individual determiner, adjective or noun.  (Adjacent chunks would then
    need to be merged by another rule.)</para>

<programlisting>
AbstractChunkRule(r'(&lt;DT|JJ|NN.*&gt;)', r'{\1}', doc='chunk DT|JJ|NNX')
</programlisting>

    <para>Now suppose we wished to create a single chunk which encompassed
    a sequence consisting of a determiner followed by zero or more adjectives,
    followed by a noun.  We can also use the star operator for this:</para>

<programlisting>
AbstractChunkRule(r'(&lt;DT&gt;&lt;JJ&gt;*&lt;NN.*&gt;)', r'{\1}', doc='chunk DT,JJ,NNX')
</programlisting>

    <para>In this example, the scope of the star operator is the preceding tag
    (i.e. the material contained inside the previous pair of angle brackets).
    </para>

    <note><para>Note that the star and other regular expression operators
    behave differently depending on whether they are inside or outside the
    scope of the angle brackets.  Inside the angle brackets, the operators work
    at the character level.  Outside the angle brackets the operators apply to
    complete tags.  In other words, the angle brackets are behaving like
    ordinary parentheses in regular expressions.</para></note>

    <para>The application of chunk rules can be constrained by making use of
    the <literal>left</literal> and <literal>right</literal> context arguments.
    For example, suppose we wanted to chunk a maximal string of tags which ends
    with a verb.  Here is a possible rule:</para>

<programlisting>
AbstractChunkRule(r'(&lt;.*&gt;*)', r'{\1}', right = r'&lt;VB.*&gt;')
</programlisting>

    <note><para>Contrary to the above, for technical reasons it is
    <emphasis>not</emphasis> possible to use the left context in
    <literal>AbstractChunkRule</literal>s.  (This is because Python's
    look-behind operator requires a fixed-width pattern.)</para></note>

    <note><para>We use a special context argument to permit rules to apply
    to their own output.  The other logical possibility - embedding
    multiple parentheses in the <literal>target</literal> argument, prevents
    rules reapplying to the same context.  This is only an issue in those
    cases where the context of some rule later becomes the target of a
    separate instance of the same rule.</para></note>

    </section> <!-- Chunk Rules and Abstract Chunk Rules -->

    <section> <title> Chunk Rules and Token Strings </title>

      <para>Chunk Rules are general regular expressions which manipulate token
      strings.  In order to keep token strings well-formed, and corresponding to
      the input, a chunk rule must only add, move or delete chunk delimiters.
      Moreover, the chunk delimiters must be matching and non-nested.  Here is
      an example of a pair of rules which violate this constraint:</para>

<programlisting>
AbstractChunkRule(r'(&lt;NN&gt;)', r'{\1}', doc='chunk NNs'),
AbstractChunkRule(r'(&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;)', r'{\1}', doc='chunk NPs'),
</programlisting>

      <para>The first rule chunks single <literal>NN</literal>s, while the second
      rule tries to chunk whole noun phrases.  However, these two rules interact
      in an unintended way.  To see why this is the case, suppose the sequence to
      be chunked includes a determiner, adjective and noun in sequence:
      <literal>&lt;DT&gt;&lt;JJ&gt;&lt;NN&gt;</literal>.  The first rule will chunk
      the noun, producing <literal>&lt;DT&gt;&lt;JJ&gt;{&lt;NN&gt;}</literal>.
      The second rule cannot now match on the three tags, since there is now an
      open brace between the <literal>&lt;JJ&gt;</literal> and the
      <literal>&lt;NN&gt;</literal> which was not accounted for in the rule's
      target expression.  The second rule still applies to the
      <literal>&lt;NN&gt;</literal>, and produces
      <literal>&lt;DT&gt;&lt;JJ&gt;{{&lt;NN&gt;}}</literal>.
      This is illegal and will cause the parser to throw an exception.
      In order to diagnose the problem, set the debug flag and step through
      the execution of the parser.</para>

      <para>The problem with the above pair of rules is that they do not form part
      of a legal chunking <emphasis>strategy</emphasis>.  Once a chunk delimiter is
      inserted beside a tag, the only legal operations are to move or delete it.
      For more discussion about how to combine rules into strategies, see the
      section on chunking strategies below.</para>

    </section> <!-- Chunk Rules and Token Strings -->

    <section> <title> The REChunkParser Class </title>

    <para>The
    <ulink url="&refdoc;/nltk.rechunkparser.REChunkParser.html"
    ><literal>REChunkParser</literal></ulink>
    allows the programmer to construct a chunkparser object from a list
    (or <emphasis>cascade</emphasis>) of chunk rules.  Suppose we have a list of
    of rules and a list of tokens.  Then we can construct
    a chunkparser and apply it as follows:</para>

<programlisting>
&prompt; <command>chunker = REChunkParser(rules)</command>
&prompt; <command>chunker.parse(tokens)</command>
</programlisting>

    <para>The <literal>parse</literal> method converts its argument to the
    string encoding, applies the chunk rules in sequence, then converts the
    result to a chunk structure and returns this structure.  Here is a
    simple example using a rule we created earlier:</para>

<programlisting>
&prompt; <command>r1 = AbstractChunkRule(r'(&lt;DT&gt;&lt;JJ&gt;*&lt;NN&gt;)', r'{\1}', doc="chunking &lt;DT&gt;&lt;JJ&gt;*&lt;NN&gt;")</command>
&prompt; <command>cp = REChunkParser([r1])</command>
&prompt; <command>chunked_sent = cp.parse(unchunked_sent)</command>
[['the'/'DT'@[1word], 'little'/'JJ'@[2word], 'cat'/'NN'@[3word]],
'sat'/'VBD'@[5word], 'on'/'IN'@[6word], ['the'/'DT'@[8word], 'mat'/'NN'@[9word]]]
</programlisting>

    <para>The <literal>REChunkParser</literal> initializer has an optional
    second argument which is a debug flag.  If this is set (e.g. to 1) then
    the chunk parser will display diagnostic output.  We repeat the above
    example with the debug flag set:</para>

<programlisting>
&prompt; <command>r1 = AbstractChunkRule(r'(&lt;DT&gt;&lt;JJ&gt;*&lt;NN&gt;)', r'{\1}', doc="chunking &lt;DT&gt;&lt;JJ&gt;*&lt;NN&gt;")</command>
&prompt; <command>cp = REChunkParser([r1], 1)</command>
&prompt; <command>chunked_sent = cp.parse(unchunked_sent)</command>

chunking &lt;DT&gt;&lt;JJ&gt;*&lt;NN&gt;:
left:
target: ((?:&lt;[^/]*/(?:DT)@\d+&gt;)(?:&lt;[^/]*/(?:JJ)@\d+&gt;)*(?:&lt;[^/]*/(?:NN)@\d+&gt;))
right:
action: {\1}
input:   &lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;  &lt;VBD&gt;  &lt;IN&gt;  &lt;DT&gt;  &lt;NN&gt;
   -&gt;   {&lt;DT&gt;  &lt;JJ&gt;  &lt;NN&gt;} &lt;VBD&gt;  &lt;IN&gt; {&lt;DT&gt;  &lt;NN&gt;}
</programlisting>

    </section> <!-- The REChunkParser Class -->

    <section> <title> Chunking Strategies </title>

      <para>There are a surprising number of different ways to chunk a
      sentence.  The chunk rules can add, shift and remove chunk delimiters
      in many ways, and the chunk rules can be combined in many ways.
      One can use a small number of very complex rules, or a long sequence of
      much simpler rules.  This section gives a brief overview of the main
      approaches.</para>

      <section> <title> Static vs Iterative Chunking </title>

        <para>In static chunking we write a single regular expression which
        accomplishes the chunking of a certain type of phrase in a single step.
        We have already seen an example of this, which is repeated below:</para>

<programlisting>
AbstractChunkRule(r'(&lt;DT&gt;&lt;JJ&gt;*&lt;NN&gt;)', r'{\1}', doc="chunking &lt;DT&gt;&lt;JJ&gt;*&lt;NN&gt;")
</programlisting>

        <para>This single rule identifies a particular kind of noun phrase chunk
        using a single regular expression.</para>

        <para>It is possible to do the same thing iteratively.  We start by chunking
        nouns, then move the left delimiter leftwards:</para>

<programlisting>
AbstractChunkRule(r'(&lt;NN.*&gt;)', r'{\1}', doc="chunking NN")
AbstractChunkRule(r'(&lt;DT|JJ&gt;){', r'{\1', right=r'&lt;JJ|NN.*&gt;', doc="shifting delimiter left"
</programlisting>

        <note><para>The second rule is unable to apply to its own output.
        To apply this maximally it is necessary to invoke it many times over.</para></note>

        <para>Another iterative approach which is easier to use begins by
        putting everything into its own chunk, then removing chunk boundaries:</para>

<programlisting>
AbstractChunkRule(r'(&lt;.*&gt;)', r'{\1}', doc="chunking every tag")
DT_JJ_NNX = r'&lt;DT|JJ|NN.*&gt;'
AbstractChunkRule('('+DT_JJ_NNX+')}{', r'\1', right=DT_JJ_NNX,
                  doc="chunk any groups of &lt;DT&gt; &lt;JJ&gt; and &lt;NNX&gt;")
</programlisting>

    </section> <!-- Static vs Iterative Chunking -->

    <section> <title> Chunking vs Chinking </title>

      <para>Chunking begins with an unchunked sentence and adds chunk
      delimiters.  The dual approach, known as <emphasis>chinking</emphasis>
      begins with the entire sentence in a single chunk then removes,
      or <emphasis>unchunks</emphasis>, pieces which cannot be part of a
      chunk.  This is convenient in situations where it is relatively
      easy to specify those tags and sequences of tags which
      <emphasis>cannot</emphasis> be in a chunk.</para>

      <para>For example, we could chunk a whole sentence then
      chink the verbs using the following rules:</para>

<programlisting>
AbstractChunkRule(r'(.*)', r'{\1}', doc='chunk the entire sentence')
AbstractChunkRule(r'(&lt;VB.*&gt;)', r'}\1{', doc='chink the verbs')
</programlisting>

      <para>Note the directionality of the braces in the second argument
      of the second constructor - they face outwards.  Thus, the closing
      brace closes the chunk which started at the beginning of the sentence
      (or after the previous verb).  Similarly, the opening brace begins
      a new chunk which goes to the end of the sentence (or the next verb).</para>

    </section> <!-- Chunking vs Chinking -->
    
  </section> <!-- Chunking Strategies -->

  <section> <title> Evaluating Chunk Parsers </title>

    <para> An easy way to evaluate a chunk parser is to take some
    already chunked text, strip off the chunks, rechunk it, and compare
    the result with the original chunked text.  NLTK provides the necessary
    functions:</para>

<programlisting>
unchunked_sent = unchunk(correct_chunks)
chunker = REChunkParser(rules)
chunked_sent = cp.parse(unchunked_sent)
score(correct_chunks, chunked_sent)
</programlisting>

    <para>The 
    <ulink url="&refdoc;/nltk.rechunkparser.score.html"
    ><literal>score</literal></ulink>
    function takes the correctly chunked sentence as its first argument, and
    the newly chunked version as its second argument, and compares them.
    It reports the fraction of actual chunks that were found (recall), the
    fraction of hypothesized chunks that were correct (precision), and a
    combined score, the F-measure (the harmonic mean of precision and recall).
    </para>

  </section> <!-- Evaluating Chunk Parsers -->

  </section>

</article>
