<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN"
"../../docbook/sgml/docbook/xml-dtd-4.2/docbookx.dtd" [
<!-- Base URL for the reference & tutorial documentation -->
<!ENTITY refdoc "../../api/public">
<!ENTITY tutdoc "..">

<!-- Dotted Rules -->
<!ENTITY dot "&bull;">
<!ENTITY A "<replaceable>A</replaceable>">
<!ENTITY B "<replaceable>B</replaceable>">
<!ENTITY i "<replaceable>i</replaceable>">
<!ENTITY j "<replaceable>j</replaceable>">
<!ENTITY k "<replaceable>j</replaceable>">
<!ENTITY d "<replaceable>d</replaceable>">
<!ENTITY n "<replaceable>n</replaceable>">
<!ENTITY c1 "<replaceable>c<subscript>1</subscript></replaceable>">
<!ENTITY cd "<replaceable>c<subscript>d</subscript></replaceable>">
<!ENTITY e1 "<replaceable>e<subscript>1</subscript></replaceable>">
<!ENTITY ed "<replaceable>e<subscript>d</subscript></replaceable>">
<!ENTITY cdplus1 "<replaceable>c<subscript>d+1</subscript></replaceable>">
<!ENTITY cn "<replaceable>c<subscript>n</subscript></replaceable>">
<!ENTITY w "<replaceable>w</replaceable>">
<!ENTITY wi "<replaceable>w<subscript>i</subscript></replaceable>">
<!ENTITY wj "<replaceable>w<subscript>j-1</subscript></replaceable>">

<!-- Index -->
<!ENTITY index SYSTEM "index.xml">

<!-- Copyright & License -->
<!ENTITY copyright SYSTEM "../copyright.xml">

<!-- Prompts for Python code samples -->
<!ENTITY prompt "<prompt>&gt;</prompt><prompt>&gt;</prompt><prompt>&gt;</prompt>">
<!ENTITY prompt2 "<prompt>...</prompt>">
]>

<article>
  <articleinfo>
    <author><firstname>Edward</firstname><surname>Loper</surname></author>
    <authorinitials>edl</authorinitials>
    <author><firstname>Steven</firstname><surname>Bird</surname></author>
    <authorinitials>sb</authorinitials>
    <title>NLTK Tutorial: Chart Parsing</title>
    &copyright;
  </articleinfo>

<!--  <section> <title> Introduction </title>

    <para></para>

X.1 introduction: motivation, background, history
    - why is this an interesting problem for CL?

  </section>

    <section> <title> Linguistic Overview </title>

    <para></para>

X.2 linguistic overview (for non-linguist readers)
    - how have linguists addressed the problem?
    - what are the shortcomings of the non-computational approach?

    </section>

    <section> <title> Computational Approaches to Chart Parsing </title>

    <para></para>

X.3 computational model (gentle for linguistics ugrads)
    - what are some good data structures and algorithms?
    - just pick one or two approaches, not encyclopedic
    - NLTK demo - watch the execution of the algorithm
      (screen shots to show execution, side bars to say how
       to do it)

    </section>

    <section> <title> Advanced Topics in Chart Parsing (optional) </title>

    <para></para>

X.4 advanced topics (optional)
    - other approaches, evaluation, problems
    - challenges for particular languages / language families
    - research questions

    </section>

    <section> <title> Chart Parsing in NLTK </title>

X.5 implementation
    - how does NLTK do it?
    - simple problems and worked solutions
    - suggested projects (e.g. for your MSc students)
-->

<!--  <section> <title> Chart Parsing </title>-->


  <!-- ============= Introduction ============= -->
  <section id="intro">
    <title> Introduction </title>

    <para>The simple parsers discussed in <ulink
    url="&tutdoc;/parsing">the parsing tutorial</ulink> have
    significant limitations.  The bottom-up shift-reduce parser can
    only find one parse, and it often fails to find a parse even if
    one exits.  The top-down recursive-descent parser can be very
    inefficient, since it often builds and discards the same
    sub-structure many times over; and if the grammar contains
    left-recursive rules, it can enter into an infinite loop. </para>

    <para> These completeness and efficiency problems can be addressed
    by employing a technique called <glossterm>dynamic
    programming</glossterm>, which stores intermediate results, and
    re-uses them when appropriate.</para>

    <para>In general, a parser hypothesizes constituents based on the
    grammar and its current knowledge about the tokens it has seen and
    the constituents it has already found.  Any constituent that is
    consistent with the current knowledge can be hypothesized; but
    many of these hypothesized constituents may not be used in
    complete parses. </para>

    <para> A <glossterm>chart parser</glossterm> uses a structure
    called a <glossterm>chart</glossterm> to record the hypothesized
    constituents in a sentence.  One way to envision this chart is as
    a graph whose nodes are the word boundaries in a sentence.  For
    example, an empty chart for the sentence "John likes Mary" can be
    drawn as:</para>
    <graphic fileref="images/intro_emptychart" scale="50"/>

    <para> Each hypothesized constituent is drawn as an
    <glossterm>edge</glossterm> in this graph.  For example, the
    following chart hypothesizes that "likes" is a V and "Mary" is an
    NP: </para>

    <graphic fileref="images/intro_2edges" scale="50"/>

    <para> And the following chart also hypothesizes that "likes Mary"
    is a VP: </para>

    <graphic fileref="images/intro_3edges" scale="50"/>

    <para> In addition to recording a constituent's type, it is also
    useful to record the types of its children.  In other words, we
    can associate a single CFG production with an edge, rather than
    just its nonterminal type: </para>

    <graphic fileref="images/intro_prodedge" scale="50"/>

    <para> All of the edges that we've seen so far represent complete
    constituents.  However, it can also be helpful to hypothesize
    <emphasis>incomplete</emphasis> constituents.  For example, we
    might want to record the hypothesis that "the V constituent
    <emphasis>likes</emphasis> forms the beginning of a VP."  We can
    record hypotheses of this form by adding a
    <glossterm>dot</glossterm> to the edge's right hand side.  The
    children to the left of the dot specify what children the
    constituent starts with; and the children to the right of the dot
    specify what children still need to be found in order to form a
    complete constituent.  For example, the edge in the following
    chart records the hypothesis that "a VP starts with the V
    <emphasis>likes</emphasis>, but still needs an NP to become
    complete": </para>

    <graphic fileref="images/intro_dottededge" scale="50"/>

    <para> These <glossterm>dotted edges</glossterm> are used to
    record all of the hypotheses that a chart parser makes about
    constituents in a sentence.  Formally, we can define a dotted edge
    as follows: </para>

    <blockquote>
      <para> A dotted edge [&A; &rarr; &c1; ... &cd; &dot; &cdplus1;
      ...  &cn;]@[&i;:&j;] records the hypothesis that a constituent
      of type &A; starts with children &c1;...&cd; covering words
      &wi;...&wj;, but still needs children &cdplus1;...&cn; to be
      complete. </para>
      <para> (where both &c1;...&cd; and &cdplus1;...&cn; may be
      empty.)</para>
    </blockquote>

    <para> If &d;=&n; (i.e., if &cdplus1;...&cn; is empty) then the
    edge represents a complete constituent, and is called a
    <glossterm>complete edge</glossterm>.  Otherwise, the edge
    represents an incomplete constituent, and is called an
    <glossterm>incomplete edge</glossterm>.  In the following chart,
      [VP&rarr;V NP&dot;]@[1:3] is a complete edge, and 
      [VP&rarr;V&dot;NP]@[1:2] is an incomplete edge.
    </para>

    <graphic fileref="images/intro_incomplete" scale="50"/>
    
    <para> If &n;=0 (i.e., if &c1;...&cn; is empty), then the edge is
    called a <glossterm>self-loop edge</glossterm>.  In the following
    chart, [VP&rarr;&dot;V NP]@[1:1] is a self-loop edge. </para>

    <graphic fileref="images/intro_selfloop" scale="50"/>

    <para> If a complete edge spans the entire sentence, and has the
    grammars' start symbol as its left-hand side, then the edge is
    called a <glossterm>parse edge</glossterm>, and it encodes one or
    more parse trees for the sentence.  In the following chart,
    [S&rarr;NP V&dot;]@[0:3] is a parse edge. </para>
      
    <graphic fileref="images/intro_parseedge" scale="50"/>

  </section> <!-- Intro -->
  <section id="chartparse">
    <title> Chart Parsing </title>

      <para> To parse a sentence, a chart parser first creates an
      empty chart spanning the sentence.  It then finds edges that are
      licensed by its knowledge about the sentence, and adds them to
      the chart one at a time until one or more parse edges are found.
      The edges that it adds can be licensed in one of three ways:
      </para>

      <itemizedlist>
        <listitem><para> The <emphasis>sentence</emphasis> can license
        an edge.  In particular, each word &wi; in the sentence
        licenses the complete edge
        [&wi;&rarr;&dot;]@[&i;:&i;+1]. </para>
        </listitem>
        <listitem><para> The <emphasis>grammar</emphasis> can license
        an edge.  In particular, each grammar production
        &A;&rarr;&alpha; licenses the self-loop edge
        [&A;&rarr;&dot;&alpha;]@[&i;:&i;] for every &i;, 0&le;&i;<&n;.
        </para>
        </listitem>
        <listitem><para> The <emphasis>current chart
        contents</emphasis> can license an edge.
          </para>
        </listitem>
      </itemizedlist>

      <para> However, it is not wise to add <emphasis>all</emphasis>
      licensed edges to the chart, since many of them will not be used
      in any complete parse.  For example, even though the edge in the
      following chart is licensed (by the grammar), it will never be
      used in a complete parse: </para>
        
      <graphic fileref="images/useless_edge" scale="50"/>

      <para> Chart parsers therefore use a set of
      <glossterm>rules</glossterm> to heuristically decide when an
      edge should be added to a chart.  This set of rules, along with
      a specification of when they should be applied, forms a
      <glossterm>strategy</glossterm>. </para>

      <section id="chartparse.fr">
        <title> The Fundamental Rule </title>

        <para> One rule is particularly important, since it is used by
        every chart parser: the <glossterm>fundamental
        rule</glossterm>.  This rule is used to combine an incomplete
        edge that's expecting a nonterminal &B; with a complete edge
        immediately following it whose left hand side is &B;.
        Formally, it states that if the chart contains the edges:</para>
        <graphic fileref="images/fr1" scale="50"/>
        <itemizedlist>
          <listitem><para>
              [&A;&rarr;&alpha;&dot;&B;&beta;]@[&i;:&j;]</para>
          </listitem>
          <listitem><para>
              [&B;&rarr;&gamma;&dot;]@[&j;:&k;]</para>
          </listitem>
        </itemizedlist>
        <para>Then the parser should add the edge: </para>
        <graphic fileref="images/fr2" scale="50"/>
        <itemizedlist>
          <listitem><para>
              [&A;&rarr;&alpha;&B;&dot;&beta;]@[&i;:&k;]</para>
          </listitem>
        </itemizedlist>

      </section> <!-- The Fundamental Rule -->

      <section>
        <title> Bottom Up Parsing </title>

        <para> To create a bottom-up parser, we need to add two rules:
        the <glossterm>Bottom-Up Initialization Rule</glossterm>; and
        the <glossterm>Bottom-Up Predict Rule</glossterm>. </para>

      <section>
        <title> The Bottom-Up Initialization Rule </title>
        
        <para> The Bottom-Up Initialization Rule says to add all edges
        licensed by the sentence.  In particular, it states that for every
        word &wi;, the parser should add the edge:</para>
        <graphic fileref="images/bu_init" scale="50"/>
        <itemizedlist>
          <listitem><para>
              [&wi;&rarr;&dot;]@[&i;:&i;+1]</para>
          </listitem>
        </itemizedlist>

      </section> <!-- Bottom-up init -->
      <section>
        <title> The Bottom-Up Predict Rule </title>

        <!-- ouch: write this better! :) --> <para> The Bottom-Up
        Predict Rule says that if the chart contains a complete edge,
        then the parser add a self-loop edge at the complete edge's
        left boundary for each grammar production whose right-hand
        side begins with the completed edge's left-hand side.  In
        other words, it states that if the chart contains the complete
        edge: </para>
        <graphic fileref="images/bu_predict1" scale="50"/>
        <itemizedlist>
          <listitem><para>
              [&A;&rarr;&alpha;&dot;]@[&i;:&j;]</para>
          </listitem>
        </itemizedlist>
        <para>&A;nd the grammar contains the production:</para>
        <itemizedlist>
          <listitem><para>
              &B;&rarr;&A; &beta;</para>
          </listitem>
        </itemizedlist>
        <para>Then the parser should add the self-loop edge:</para>
        <graphic fileref="images/bu_predict2" scale="50"/>
        <itemizedlist>
          <listitem><para>
              [&B;&rarr;&dot;&beta;]@[&i;:&i;]</para>
          </listitem>
        </itemizedlist>
        
      </section> <!-- Bottom-up predict -->

      <section> 
        <title> The Bottom-Up Parsing Strategy </title>

        <para> Using these three rules, we can parse a sentence as
        follows: </para>

        <itemizedlist>
          <listitem><para> Create an empty chart spanning the
          sentence. </para>
          </listitem>
          <listitem><para> Apply the Bottom-Up Initialization Rule to
          each word. </para>
          </listitem>
          <listitem><para> Until no more edges are added: </para>
            <itemizedlist>
              <listitem><para> Apply the Bottom-Up Predict Rule
              everywhere it applies. </para>
              </listitem>
              <listitem><para> Apply the Fundamental Rule everywhere
              it applies. </para>
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem><para> Return all of the parse trees corresponding
          to the parse edges in the chart. </para>
          </listitem>
        </itemizedlist>

        <para> For example, the following diagram shows the order in
        which get added when applying bottom-up parsing to a simple
        example sentence: </para>
        
        <graphic fileref="images/bottom_up_chart" scale="50"/>

      </section> <!-- Strategy -->
    </section> <!-- Bottom-Up Parsing -->

    <section>
      <title> Top-Down Parsing </title>

      <para> To create a bottom-up parser, we need to use the
      Fundamental Rule plus three other rules: the <glossterm>Top-Down
      Initialization Rule</glossterm>, the <glossterm>Top-Down Expand
      Rule</glossterm>, and the <glossterm>Top-Down Match
      Rule</glossterm>. </para>

      <section>
        <title> Top-Down Initialization Rule </title>

        <para> The top-down initialization rule captures the fact that
        root of any parse must be the start symbol.  It states that
        for every grammar production: </para>
        <itemizedlist>
          <listitem><para>
                S&rarr;&alpha;</para>
          </listitem>
        </itemizedlist>
        <para> The parser should add the self-loop edge: </para>
        <graphic fileref="images/td_init" scale="50"/>
        <itemizedlist>
          <listitem><para>
                [S&rarr;&dot;&alpha;]@[0:0]</para>
          </listitem>
        </itemizedlist>

      </section> <!-- Top down init Rule -->
      
      <section>
        <title> Top-Down Expand Rule </title>

        <para> The top-down expand rule says that if the chart
        contains an incomplete edge whose dot is followed by a
        nonterminal &B;, then the parser should add any self-loop
        edges licensed by the grammar whose left-hand side is &B;.  In
        particular, if the chart contains the incomplete edge: </para>
        <graphic fileref="images/td_expand1" scale="50"/>
        <itemizedlist>
          <listitem><para>
                [&A;&rarr;&alpha;&dot;&B;&beta;]@[&i;:&j;]</para>
          </listitem>
        </itemizedlist>
        <para> Then for each grammar production: </para>
        <itemizedlist>
          <listitem><para>
                &B;&rarr;&gamma;</para>
          </listitem>
        </itemizedlist>
        <para> The parser should add the edge: </para>
        <graphic fileref="images/td_expand2" scale="50"/>
        <itemizedlist>
          <listitem><para>
                [&B;&rarr;&dot;&gamma;]@[&j;:&j;]</para>
          </listitem>
        </itemizedlist>

      </section> <!-- Top down init Rule -->

      <section>
        <title> Top-Down Match Rule </title>

        <para> The top-down match rule says that if the chart contains
        an incomplete edge whose dot is followed by a terminal &w;,
        then the parser should add an edge if the terminal corresponds
        to the text.  In particular, if the chart contains the
        incomplete edge:</para>
        <graphic fileref="images/td_match1" scale="50"/>
        <itemizedlist>
          <listitem><para>
              [A&rarr;&alpha;&dot;&wj;&beta;]@[&i;:&j;]</para>
          </listitem>
        </itemizedlist>
        <para> Then the parser should add the complete edge: </para>
        <graphic fileref="images/td_match2" scale="50"/>
        <itemizedlist>
          <listitem><para>
              [&wj;&rarr;&dot;]@[&j;:&j;+1]</para>
          </listitem>
        </itemizedlist>

      </section> <!-- Top-down match Rule -->

      <section> 
        <title> The Top-Down Parsing Strategy </title>

        <para> Using these four rules, we can parse a sentence as
        follows: </para>

        <itemizedlist>
          <listitem><para> Create an empty chart spanning the
          sentence. </para>
          </listitem>
          <listitem><para> Apply the Top-Down Initialization Rule to
          each word. </para>
          </listitem>
          <listitem><para> Until no more edges are added: </para>
            <itemizedlist>
              <listitem><para> Apply the Top-Down Expand Rule
              everywhere it applies. </para>
              </listitem>
              <listitem><para> Apply the Top-Down Match Rule
              everywhere it applies. </para>
              </listitem>
              <listitem><para> Apply the Fundamental Rule everywhere
              it applies. </para>
              </listitem>
            </itemizedlist>
          </listitem>
          <listitem><para> Return all of the parse trees corresponding
          to the parse edges in the chart. </para>
          </listitem>
        </itemizedlist>

        <para> For example, the following diagram shows the order in
        which get added when applying bottom-up parsing to a simple
        example sentence: </para>

        <graphic fileref="images/top_down_chart" scale="50"/>

      </section> <!-- Strategy -->
    </section> <!-- Top down parsing -->
      

          
  </section> <!-- Chart Parsing -->

  <section>
    <title> Chart Parsing in NLTK </title>

    <section>
      <title> Edges </title>
      
      <para> NLTK defines two classes for encoding edges: </para>

      <itemizedlist>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.LeafEdge-class.html"><literal
        >LeafEdge</literal></ulink> is used to encode edges of the
        form [&wi;&rarr;&dot;]@[&i;:&i;+1]. </para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.TokenEdge-class.html"><literal
        >TokenEdge</literal></ulink> is used to encode edges of the
        form [&A;&rarr;&alpha;&dot;&beta;]@[&i;:&j;]. </para>
        </listitem>
      </itemizedlist>

      <para><literal>LeafEdges</literal> are constructed from a leaf
      terminal and an index: </para>
      
<programlisting><![CDATA[
# Construct a tree edge.
>>> edge2=LeafEdge('dog', 3)
[Edge: 'dog' -> *]@[3:4w]
]]></programlisting>

      <para><literal>TreeEdges</literal> are constructed from a span,
      a left-hand side, a right-hand side, and a dot position: </para>
      
<programlisting><![CDATA[
# Construct a tree edge.
>>> V, NP, PP = nonterminals('V NP PP')
>>> edge1=TreeEdge((3,7), VP, [V,NP,PP], 2)
[Edge: VP -> V NP * PP]@[3:7w]
]]></programlisting>

      <para>The convenience function <ulink
      url="&refdoc;/nltk.parser.chart.LeafEdge-class.html#from_production"
      ><literal>TreeEdge.from_production</literal></ulink> creates the
      <literal>TreeEdge</literal> licensed by a given CFG production:
      </para>
        
<programlisting><![CDATA[
# Construct a CFG production
>>> prod = CFGProduction.parse('S->NP VP')[0]
>>> index = 3
>>> edge3 = TreeEdge.from_production(prod, 3)
[Edge: S -> * NP VP]@[3:3]
]]></programlisting>

      <para>Both <literal>TreeEdge</literal> and
      <literal>LeafEdge</literal> implement the <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI-class.html"><literal
      >EdgeI</literal></ulink> interface, which defines the methods
      that all edges should support: </para>

<programlisting><![CDATA[
# The edge's span, start, end, and length
>>> edge1.span()
(3,6)
>>> edge1.start()
3
>>> edge1.end()
7
>>> edge1.length()
4

# The edge's left-hand side and right-hand side.
>>> edge1.lhs()
<VP>
>>> edge1.rhs()
(<V>, <NP>, <PP>)

# The edge's dot position.
>>> edge1.dot()
2

# Is it a complete edge?
>>> edge1.is_complete()
False
>>> edge1.is_incomplete()
True

# The next RHS element after the dot
>>> edge1.next()
<PP>
>>> edge2.next()
None
]]></programlisting>

    </section> <!-- Edges -->

    <section>
      <title> Charts </title>

      <para> Charts are encoded using the <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html"
      ><literal>Chart</literal></ulink> class.  To create an empty
      chart spanning a given sentence, use the <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#__init__"
      ><literal>Chart</literal> constructor</ulink>:</para>

<programlisting><![CDATA[
>>> text = Token(TEXT='James wears a hat')
>>> WhitespaceTokenizer().tokenize(text)
>>> chart = Chart(text, LEAF='TEXT')
]]></programlisting>

      <!-- Talk about child pointer lists & reconstruction earlier! 
      --> <para> New edges are added to the chart using the <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#insert"
      ><literal>insert</literal></ulink> method, which takes an edge
      and a child pointer list.  A <glossterm>child pointer
      list</glossterm> is a list of edges &e1;...&ed;, specifying the
      edges that licensed each child to the left of the dot.  It is
      used to reconstruct the parse trees once parsing is
      finished. </para>
      
<programlisting><![CDATA[
>>> NP, N = nonterminals('NP N')
>>> edge1 = LeafEdge('hat', 3)
>>> edge2 = TreeEdge((3,3), NP, [N], 0)
>>> edge3 = TreeEdge((3,4), NP, [N], 1)
>>> chart.insert(edge1, [])
>>> chart.insert(edge2, [])
>>> chart.insert(edge3, [edge1])
        
# Pretty-print the chart: 
>>> print chart.pp()
|.  James  .  wears  .    a    .   hat   .|
|.         .         .         >         .| NP -> * N 
|.         .         .         [---------]| NP -> N * 
|.         .         .         [---------]| 'hat'. 
]]></programlisting>


      <para> The leaves of the chart's token can be accessed with the
      methods <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#num_leaves"
      ><literal>num_leaves</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#leaf"
      ><literal>leaf</literal></ulink>, and <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#leaves"
      ><literal>leaves</literal></ulink>.  Note that this methods
      return the leaf properties of the words, and not the word tokens
      themselves: </para>
      
<programlisting><![CDATA[
>>> chart.num_leaves()
4
>>> chart.leaf(1)
'wears'
>>> chart.leaves()
['James', 'wears', 'a', 'hat']
]]></programlisting>

      <para> The chart's edges can be accessed with the methods <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#num_edges"
      ><literal>num_edges</literal></ulink> and <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#edges"
      ><literal>edges</literal></ulink>: </para>

<programlisting><![CDATA[
>>> chart.num_edges()
3
>>> for edge in chart.edges(): print edge
[Edge: 'hat' -> *]@[3:4w]
[Edge: NP -> * N]@[3:3w]
[Edge: NP -> N *]@[3:4w]
]]></programlisting>

      <para> The <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#select"
      ><literal>select</literal></ulink> method can be used to
      efficiently retrieve all edges that satisfy one or more
      restrictions: </para>

<programlisting><![CDATA[
Edges whose span starts at 3.
>>> for edge in chart.select(start=3): print edge
[Edge: 'hat' -> *]@[3:4w]
[Edge: NP -> * N]@[3:3w]
[Edge: NP -> N *]@[3:4w]
Edges whose left hand side is NP.
>>> for edge in chart.select(lhs=NP): print edge
[Edge: NP -> * N]@[3:3w]
[Edge: NP -> N *]@[3:4w]
Edges whose span length is 1.
>>> for edge in chart.select(length=1): print edge
[Edge: 'hat' -> *]@[3:4w]
[Edge: NP -> N *]@[3:4w]
Edges whose left hand side is NP and whose length is 1.
>>> for edge in chart.select(lhs=NP, length=1): print edge
[Edge: NP -> N *]@[3:4w]
]]></programlisting>

      <para> The following attributes can be given as restrictions to
      <literal>select</literal>: <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#span"
      ><literal>span</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#start"
      ><literal>start</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#end"
      ><literal>end</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#length"
      ><literal>length</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#lhs"
      ><literal>lhs</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#rhs"
      ><literal>rhs</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#next"
      ><literal>next</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#dot"
      ><literal>dot</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#is_complete"
      ><literal>is_complete</literal></ulink>, <ulink
      url="&refdoc;/nltk.parser.chart.EdgeI.html#is_incomplete"
      ><literal>is_incomplete</literal></ulink>. </para>

      <para> The <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#trees"
      ><literal>trees</literal></ulink> method returns a list of the
      trees that are associated with a given edge; and the <ulink
      url="&refdoc;/nltk.parser.chart.Chart.html#parses"
      ><literal>parses</literal></ulink> method returns a list of the
      parse trees for a given start symbol: </para>
        
<programlisting><![CDATA[
>>> chart.trees(edge3)
[(NP: <hat>)]

# After having added many more edges: 
>>> chart.parses(S)
(S: (NP: <James>) (VP: (V: <wears>) (NP: (Det: <a>) (N: <hat>))))
]]></programlisting>

    </section> <!-- Charts -->

    <section>
      <title> Chart Rules </title>

      <para> The <ulink url="&refdoc;/nltk.parser.chart.ChartRuleI"
      ><literal>ChartRuleI</literal></ulink> class defines a standard
      interface for chart rules.  Each chart rule must define the
      class variable <ulink
      url="&refdoc;/nltk.parser.chart.ChartRuleI#NUM_EDGES"><literal
      >NUM_EDGES</literal></ulink>, which specifies how many edges the
      rule applies to (e.g., two for the Fundamental Rule; one for the
      Top-Down Expand Rule; and none for the Top-Down Init Rule).
      Each chart rule must also define four methods: </para>

      <itemizedlist>
        <listitem> <para> <ulink
        url="&refdoc;/nltk.parser.chart.ChartRuleI#apply"
        ><literal>apply</literal></ulink> adds all edges licensed by
        the rule and a given set of edges to the chart; and returns a
        list of the added edges. </para>
        </listitem>
        
        <listitem> <para> <ulink
        url="&refdoc;/nltk.parser.chart.ChartRuleI#apply_everywhere"
        ><literal>apply_everywhere</literal></ulink> adds all edges
        licensed by the rule and the edges in the chart to the chart;
        and returns a list of the added edges. </para>
        </listitem>
        
        <listitem> <para> <ulink
        url="&refdoc;/nltk.parser.chart.ChartRuleI#apply_iter"
        ><literal>apply_iter</literal></ulink> is a generator function
        that adds the edges licensed by the rule and a given set of
        edges to the chart, one at a time.  Each time the generator is
        resumed, it adds a new edge and yields that edge; or
        returns. </para>
        </listitem>
        
        <listitem> <para> <ulink
        url="&refdoc;/nltk.parser.chart.ChartRuleI#apply_everywhere_iter"
        ><literal>apply_everywhere_iter</literal></ulink> is a
        generator function that adds the edges licensed by the rule
        and the edges in the chart to the chart, one at a time.  Each
        time the generator is resumed, it adds a new edge and yields
        that edge; or returns. </para>
        </listitem>
      </itemizedlist>

      <para> To simplify chart rule construction,
      <literal>nltk.parse.chart</literal> defines an abstract base
      class.  <ulink
      url="&refdoc;/nltk.parser.chart.AbstractChartRule"
      ><literal>AbstractChartRule</literal></ulink> provides default
      implementations for every method but
      <literal>apply_iter</literal>.  </para>

      <para> Currently, <literal>nltk.parse.chart</literal> defines
      the following chart rules:  </para>

      <itemizedlist>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.FundamentalRule"
        ><literal>FundamentalRule</literal></ulink>: The Fundamental
        Rule.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.TopDownInitRule"
        ><literal>TopDownInitRule</literal></ulink>: The Top Down
        Initialization Rule.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.TopDownExpandRule"
        ><literal>TopDownExpandRule</literal></ulink>: The Top Down
        Expand Rule.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.TopDownMatchRule"
        ><literal>TopDownMatchRule</literal></ulink>: The Top Down
        Match Rule.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.BottomUpInit"
        ><literal>BottomUpInit</literal></ulink>: The Bottom Up
        Initialization Rule.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.BottomUpPredictRule"
        ><literal>BottomUpPredictRule</literal></ulink>: The Bottom Up
        Predict Rule.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.CachedTopDownInitRule"
        ><literal>CachedTopDownInitRule</literal></ulink>: A cached
        version of the Top Down Initialization Rule, to avoid
        recomputing edges for the same configuration</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.CachedTopDownExpandRule"
        ><literal>CachedTopDownExpandRule</literal></ulink>: A cached
        version of the Top Down Expand Rule, to avoid recomputing
        edges for the same configuration</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.SingleEdgeFundamentalRule"
        ><literal>SingleEdgeFundamentalRule</literal></ulink>: A
        single-edged version of the Fundamental Rule, that finds edges
        to combine with from the chart</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.CompleterRule"
        ><literal>CompleterRule</literal></ulink>: A single-edged
        version of <literal>FundamentalRule</literal> used by Earley's
        algorithm.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.ScannerRule"
        ><literal>ScannerRule</literal></ulink>: A lexicon-based
        version of <literal>TopDownMatchRule</literal>, used by
        Earley's algorithm.</para>
        </listitem>
        <listitem><para> <ulink
        url="&refdoc;/nltk.parser.chart.PredictorRule"
        ><literal>PredictorRule</literal></ulink>: Another name for
        <literal>TopDownExpandRule</literal>, used by Earley's
        algorithm.</para>
        </listitem>
      </itemizedlist>

    </section> <!-- Chart Rules -->

    <section>
      <title> ChartParser </title>

      <para> <literal>nltk.parse.chart</literal> defines a simple yet
      flexible chart parser, <ulink
      url="&refdoc;/nltk.parser.chart.ChartParser"
      ><literal>ChartParser</literal></ulink>.  A new
      <literal>ChartParser</literal> is constructed from a grammar and
      a list of chart rules (also known as a
      <glossterm>strategy</glossterm>).  These rules will be applied,
      on order, until no new edges are added to the chart.  In
      particular, <literal>ChartParser</literal> uses the following
      algorithm:
      </para>

      <itemizedlist>
        <listitem><para> Until no new edges are added:</para>
          <itemizedlist>
            <listitem><para> For each chart rule
            <replaceable>R</replaceable>: </para>
              <itemizedlist>
                <listitem><para> Apply <replaceable>R</replaceable> to any
                    applicable edges in the chart. </para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
        </listitem>
        <listitem><para> Return any complete parses in the chart. </para>
        </listitem>
      </itemizedlist>

      <para> <literal>nltk.parse.chart</literal> defines two pre-made
      strategies: <literal>TD_STRATEGY</literal>, a basic top-down
      strategy; and <literal>BU_STRATEGY</literal>, a basic bottom-up
      strategy.  When constructing a <literal>ChartParser</literal>,
      you can use either of these strategies, or create your own. </para>

      <para> The following example illustrates the use of
      <literal>ChartParser</literal>:</para>

<programlisting><![CDATA[
>>> from nltk.tokenizer import *
>>> from nltk.parser.chart import *

# Define a simple grammar.
>>> grammar = CFG.parse('''
...   S -> NP VP
...   VP -> V NP | VP PP
...   V -> "saw" | "ate"
...   NP -> "John" | "Mary" | "Bob" | Det N | NP PP
...   Det -> "a" | "an" | "the" | "my"
...   N -> "dog" | "cat" | "cookie"
...   PP -> P NP
...   P -> "on" | "by" | "with"
...   ''')

# Create and tokenize a sentence token.
>>> sent = Token(TEXT='John saw a cat with my cookie')
>>> WhitespaceTokenizer().tokenize(sent)

# Parse the sentence, bottom-up.
>>> parser = ChartParser(grammar, BU_STRATEGY, LEAF='TEXT')
>>> parser.parse_n(sent)
>>> for tree in sent['TREES']: print tree
(S:
  (NP: <John>)
  (VP:
    (VP: (V: <saw>) (NP: (Det: <a>) (N: <cat>)))
    (PP: (P: <with>) (NP: (Det: <my>) (N: <cookie>)))))
(S:
  (NP: <John>)
  (VP:
    (V: <saw>)
    (NP:
      (NP: (Det: <a>) (N: <cat>))
      (PP: (P: <with>) (NP: (Det: <my>) (N: <cookie>))))))
]]></programlisting>

      <para> The <literal>trace</literal> parameter can be specified
      when creating a parser, to turn on tracing (higher trace levels
      produce more verbose output).  The following examples show the
      trace output for parsing the same sentence with both the
      top-down and the bottom-up strategies. </para>

<programlisting><![CDATA[
# Parse the sentence, bottom-up, with tracing turned on.
>>> parser = ChartParser(grammar, BU_STRATEGY, LEAF='TEXT', trace=2)
>>> parser.parse_n(sent)
|. John. saw .  a  . cat . with.  my .cooki.|
Bottom Up Init Rule:
|[-----]     .     .     .     .     .     .| 'John'. 
|.     [-----]     .     .     .     .     .| 'saw'. 
|.     .     [-----]     .     .     .     .| 'a'. 
|.     .     .     [-----]     .     .     .| 'cat'. 
|.     .     .     .     [-----]     .     .| 'with'. 
|.     .     .     .     .     [-----]     .| 'my'. 
|.     .     .     .     .     .     [-----]| 'cookie'. 
Bottom Up Predict Rule:
|>     .     .     .     .     .     .     .| NP -> * 'John' 
|.     >     .     .     .     .     .     .| V  -> * 'saw' 
|.     .     >     .     .     .     .     .| Det -> * 'a' 
|.     .     .     >     .     .     .     .| N  -> * 'cat' 
|.     .     .     .     >     .     .     .| P  -> * 'with' 
|.     .     .     .     .     >     .     .| Det -> * 'my' 
|.     .     .     .     .     .     >     .| N  -> * 'cookie' 
Fundamental Rule:
|[-----]     .     .     .     .     .     .| NP -> 'John' * 
|.     [-----]     .     .     .     .     .| V  -> 'saw' * 
|.     .     [-----]     .     .     .     .| Det -> 'a' * 
|.     .     .     [-----]     .     .     .| N  -> 'cat' * 
|.     .     .     .     [-----]     .     .| P  -> 'with' * 
|.     .     .     .     .     [-----]     .| Det -> 'my' * 
|.     .     .     .     .     .     [-----]| N  -> 'cookie' * 
Bottom Up Predict Rule:
|>     .     .     .     .     .     .     .| S  -> * NP VP 
|>     .     .     .     .     .     .     .| NP -> * NP PP 
|.     >     .     .     .     .     .     .| VP -> * V NP 
|.     .     >     .     .     .     .     .| NP -> * Det N 
|.     .     .     .     >     .     .     .| PP -> * P NP 
|.     .     .     .     .     >     .     .| NP -> * Det N 
Fundamental Rule:
|[----->     .     .     .     .     .     .| S  -> NP * VP 
|[----->     .     .     .     .     .     .| NP -> NP * PP 
|.     [----->     .     .     .     .     .| VP -> V * NP 
|.     .     [----->     .     .     .     .| NP -> Det * N 
|.     .     [-----------]     .     .     .| NP -> Det N * 
|.     .     .     .     [----->     .     .| PP -> P * NP 
|.     .     .     .     .     [----->     .| NP -> Det * N 
|.     .     .     .     .     [-----------]| NP -> Det N * 
|.     [-----------------]     .     .     .| VP -> V NP * 
|.     .     .     .     [-----------------]| PP -> P NP * 
|[-----------------------]     .     .     .| S  -> NP VP * 
Bottom Up Predict Rule:
|.     .     >     .     .     .     .     .| S  -> * NP VP 
|.     .     >     .     .     .     .     .| NP -> * NP PP 
|.     .     .     .     .     >     .     .| S  -> * NP VP 
|.     .     .     .     .     >     .     .| NP -> * NP PP 
|.     >     .     .     .     .     .     .| VP -> * VP PP 
Fundamental Rule:
|.     .     [----------->     .     .     .| S  -> NP * VP 
|.     .     [----------->     .     .     .| NP -> NP * PP 
|.     .     .     .     .     [----------->| S  -> NP * VP 
|.     .     .     .     .     [----------->| NP -> NP * PP 
|.     [----------------->     .     .     .| VP -> VP * PP 
|.     .     [-----------------------------]| NP -> NP PP * 
|.     [-----------------------------------]| VP -> VP PP * 
|.     .     [----------------------------->| S  -> NP * VP 
|.     .     [----------------------------->| NP -> NP * PP 
|.     [----------------------------------->| VP -> VP * PP 
|.     [-----------------------------------]| VP -> V NP * 
|[=========================================]| S  -> NP VP * 
|[=========================================]| S  -> NP VP * 
|.     [----------------------------------->| VP -> VP * PP
]]></programlisting>

      <programlisting><![CDATA[
# Parse the sentence, top-down, with tracing turned on.
>>> parser = ChartParser(grammar, TD_STRATEGY, LEAF='TEXT', trace=2)
>>> parser.parse_n(sent)
|. John. saw .  a  . cat . with.  my .cooki.|
Top Down Init Rule:
|>     .     .     .     .     .     .     .| S  -> * NP VP 
Top Down Expand Rule:
|>     .     .     .     .     .     .     .| NP -> * 'John' 
|>     .     .     .     .     .     .     .| NP -> * 'Mary' 
|>     .     .     .     .     .     .     .| NP -> * 'Bob' 
|>     .     .     .     .     .     .     .| NP -> * Det N 
|>     .     .     .     .     .     .     .| NP -> * NP PP 
|>     .     .     .     .     .     .     .| Det -> * 'a' 
|>     .     .     .     .     .     .     .| Det -> * 'an' 
|>     .     .     .     .     .     .     .| Det -> * 'the' 
|>     .     .     .     .     .     .     .| Det -> * 'my' 
Top Down Match Rule:
|[-----]     .     .     .     .     .     .| 'John'. 
Fundamental Rule:
|[-----]     .     .     .     .     .     .| NP -> 'John' * 
|[----->     .     .     .     .     .     .| NP -> NP * PP 
|[----->     .     .     .     .     .     .| S  -> NP * VP 
Top Down Expand Rule:
|.     >     .     .     .     .     .     .| PP -> * P NP 
|.     >     .     .     .     .     .     .| VP -> * V NP 
|.     >     .     .     .     .     .     .| VP -> * VP PP 
|.     >     .     .     .     .     .     .| P  -> * 'on' 
|.     >     .     .     .     .     .     .| P  -> * 'by' 
|.     >     .     .     .     .     .     .| P  -> * 'with' 
|.     >     .     .     .     .     .     .| V  -> * 'saw' 
|.     >     .     .     .     .     .     .| V  -> * 'ate' 
Top Down Match Rule:
|.     [-----]     .     .     .     .     .| 'saw'. 
Fundamental Rule:
|.     [-----]     .     .     .     .     .| V  -> 'saw' * 
|.     [----->     .     .     .     .     .| VP -> V * NP 
Top Down Expand Rule:
|.     .     >     .     .     .     .     .| NP -> * 'John' 
|.     .     >     .     .     .     .     .| NP -> * 'Mary' 
|.     .     >     .     .     .     .     .| NP -> * 'Bob' 
|.     .     >     .     .     .     .     .| NP -> * Det N 
|.     .     >     .     .     .     .     .| NP -> * NP PP 
|.     .     >     .     .     .     .     .| Det -> * 'a' 
|.     .     >     .     .     .     .     .| Det -> * 'an' 
|.     .     >     .     .     .     .     .| Det -> * 'the' 
|.     .     >     .     .     .     .     .| Det -> * 'my' 
Top Down Match Rule:
|.     .     [-----]     .     .     .     .| 'a'. 
Fundamental Rule:
|.     .     [-----]     .     .     .     .| Det -> 'a' * 
|.     .     [----->     .     .     .     .| NP -> Det * N 
Top Down Expand Rule:
|.     .     .     >     .     .     .     .| N  -> * 'dog' 
|.     .     .     >     .     .     .     .| N  -> * 'cat' 
|.     .     .     >     .     .     .     .| N  -> * 'cookie' 
Top Down Match Rule:
|.     .     .     [-----]     .     .     .| 'cat'. 
Fundamental Rule:
|.     .     .     [-----]     .     .     .| N  -> 'cat' * 
|.     .     [-----------]     .     .     .| NP -> Det N * 
|.     [-----------------]     .     .     .| VP -> V NP * 
|.     .     [----------->     .     .     .| NP -> NP * PP 
|[-----------------------]     .     .     .| S  -> NP VP * 
|.     [----------------->     .     .     .| VP -> VP * PP 
Top Down Expand Rule:
|.     .     .     .     >     .     .     .| PP -> * P NP 
|.     .     .     .     >     .     .     .| P  -> * 'on' 
|.     .     .     .     >     .     .     .| P  -> * 'by' 
|.     .     .     .     >     .     .     .| P  -> * 'with' 
Top Down Match Rule:
|.     .     .     .     [-----]     .     .| 'with'. 
Fundamental Rule:
|.     .     .     .     [-----]     .     .| P  -> 'with' * 
|.     .     .     .     [----->     .     .| PP -> P * NP 
Top Down Expand Rule:
|.     .     .     .     .     >     .     .| NP -> * 'John' 
|.     .     .     .     .     >     .     .| NP -> * 'Mary' 
|.     .     .     .     .     >     .     .| NP -> * 'Bob' 
|.     .     .     .     .     >     .     .| NP -> * Det N 
|.     .     .     .     .     >     .     .| NP -> * NP PP 
|.     .     .     .     .     >     .     .| Det -> * 'a' 
|.     .     .     .     .     >     .     .| Det -> * 'an' 
|.     .     .     .     .     >     .     .| Det -> * 'the' 
|.     .     .     .     .     >     .     .| Det -> * 'my' 
Top Down Match Rule:
|.     .     .     .     .     [-----]     .| 'my'. 
Fundamental Rule:
|.     .     .     .     .     [-----]     .| Det -> 'my' * 
|.     .     .     .     .     [----->     .| NP -> Det * N 
Top Down Expand Rule:
|.     .     .     .     .     .     >     .| N  -> * 'dog' 
|.     .     .     .     .     .     >     .| N  -> * 'cat' 
|.     .     .     .     .     .     >     .| N  -> * 'cookie' 
Top Down Match Rule:
|.     .     .     .     .     .     [-----]| 'cookie'. 
Fundamental Rule:
|.     .     .     .     .     .     [-----]| N  -> 'cookie' * 
|.     .     .     .     .     [-----------]| NP -> Det N * 
|.     .     .     .     [-----------------]| PP -> P NP * 
|.     .     .     .     .     [----------->| NP -> NP * PP 
|.     .     [-----------------------------]| NP -> NP PP * 
|.     [-----------------------------------]| VP -> VP PP * 
|.     [-----------------------------------]| VP -> V NP * 
|.     .     [----------------------------->| NP -> NP * PP 
|[=========================================]| S  -> NP VP * 
|.     [----------------------------------->| VP -> VP * PP 
|[=========================================]| S  -> NP VP * 
|.     [----------------------------------->| VP -> VP * PP 
Top Down Expand Rule:
|.     .     .     .     .     .     .     >| PP -> * P NP 
|.     .     .     .     .     .     .     >| P  -> * 'on' 
|.     .     .     .     .     .     .     >| P  -> * 'by' 
|.     .     .     .     .     .     .     >| P  -> * 'with' 
]]></programlisting>

    </section> <!-- ChartParser -->

  </section> <!-- Chart Parsing in NLTK -->

  &index;
</article>
