[?] unresolved issue about tagger training corpus mentioned in issue tracker

pxi 5up Chapters -3 -> Chapters 1-3

pxii 2d 8-Chapter 10 -> 8-10
     4d afterword -> Afterword

pxiii 4up replace the sentence:
      "Although Python 3.0 has now been released, it will be some time before 
       NLTK and the libraries it depends on are converted to use Python 3.0."
      with:
      "We are committed to porting NLTK to Python 3.0 once the libraries that
      NLTK depends on have been ported." 

pxiv 13d why is "Graphviz" in bold?

     Table P-2: maxent -> maximum entropy

pxvi data-set -> dataset

pxvii Conventions: URLs should be listed under "Italic", not "Constant width"
      "Bold" should be typeset in boldface

pxviii [?] "Using Code Examples" -- needs revising since we already distribute the code
       under an open source license, and the book itself (incl examples) under a Creative Commons license.

pxix middle: After "Linguistic Data Consortium," add "an Edward Clarence Dyason Fellowship,"

p5 8d "the _US Presidential Inaugural Addresses_" -> "the Inaugural Address Corpus"

p6 7d "joining U.S. presidential inaugural addresses end-to-end"
      -> "joining the texts of the _Inaugural Address Corpus_ end-to-end"

p6 Numpy -> NumPy

p7 5d internet -> Internet

p8 6up called function -> called a function

p17 fig 1-3 reduce scale of figure
    3up careful use -> careful to use

p26 letter "l" -> letter l [italic] (cf p36, ex 24)

p31 13d chap-data-intensive -> Chapter 5

p34 Note that there are three paragraphs but four citations.
    Happy to replace with regular citations and expand bibliography accordingly.

p34 The ACL website is http://www.aclweb.org/

p35 ex 9b: adding it -> adding the string
    ex 10b: b. b) -> b.
    ex 15: letter "b" -> letter b [italic]
    ex 25a with "sh" -> with sh [italic] 

p40 5up subsection heading: "The Brown Corpus" -> "Brown Corpus"

p43 The missing figure citation is to fig 1-2
    9up file[:4] -> fileid[:4]
    
p43 subsection title -> "Inaugural Address Corpus"
    next line: "US Presidential Inaugural Addresses corpus" -> "Inaugural Address Corpus"

p43 7up "Inaugural corpus" -> "Inaugural Address Corpus"

p44 Happy to omit the second sentence of the table caption
    Fig 2-1 caption: america, citizen s/b roman

[?] Per Ewan: "The 'Contents' column needs to be reviewed by SB."
My concern was that the hyphenation conventions being used here seem unclear.
There are several hyphenated forms that we don't use elsewhere, such as
part-of-speech and named-entity. I don't see the motivation for this. Also, we have
both "part-of-speech tagged" and "POS-tagged".

p45 Content of the table looks fine to me; note that since the CoNLL entry is wrapped,
    we might as well expand "Sel" -> "Selections"

p45 middle "Presidential Addresses"/"Ahrens" -> "State of the Union Corpus" / "CSpan"
    then realphabetized

p45 11up "SENSEVAL 2 Corpus" -> "Senseval 2 Corpus"

p46 "Your Turn": 'Language-Latin1' s/b cwi and w/o quotes (its a metavariable)

p47 Table 2-3 Delete second occurrence of "nltk.corpus.reader" in table caption.
    It should read: "more documentation can be found using help(nltk.corpus.reader)
    and by reading the online Corpus HOWTO at http://www.nltk.org/howto.

p49 10d omit single quotes around pathname (this is meant to be the location, not a string)

p50 confirming the cw italic font for metavariables is correct

p52 1,2d omit single quotes from america, Americans and make italic font

p53 Ex 2-1 caption: generate_model() s/b cw

p54 File menu, Run menu -- use cw or cwi for these cases

p57 3up "Words corpus" -> "Words Corpus"

p58 16up fail -> fails

p59 length constraint (1) -> length (1) constraints  (plural "constraints", moved circle (1))

p59 15up "Names corpus" -> "Names Corpus"

p60 to be consistent, the cited letters (a, e, i, h, l, k, o, r, s, t) s/b roman 

p67 Fig 2-8 the line joining "motor vehicle" to "go-kart" s/b vertical

p69 11d antonymy s/b bold font

p71 4d "function" -> "method name"

    15up insert closing parens after URL

p72 9d "Brown corpus" -> "Brown Corpus"; "Web text corpus" -> "Web Text Corpus"

p72 17up "Names corpus" -> "Names Corpus"

p73 q19 "like the one given above for modals"
    -> "like the one given in section 2.1 for modals"
    or "like the one given on p42 for modals"

p75 it would be nice to avoid these widowed lines if possible.
    (removing "different" from q3 would save one line)

p81 Table 3-1 caption: words in quotes s/b unquoted roman.

p84 Figure 3-1 caption: nltk.Text s/b cw

p89 Figure 3-2 caption: Monty Python s/b unquoted roman

p89 fig 3-2 scale smaller?

p90 [?] since material on strings vs lists overlaps bottom p84 / top p85,
should we add a line to say that we are reinforcing points made earlier?

p91 in 4th sent of sect 3.3, different fonts seem to be being used for the 4 
glyphs illustrating non-ASCII character sets. E.g. 3rd and 4th look larger and 
seem to be in cw font. Can this be fixed? (Similarly, p 93 13up, p94 15d)

p95 LD query: this is meant to be Python output to a terminal window, so I would
say it s/b cw.

p96 12up "Words corpus" -> "Words Corpus"

p97 Fig 3-5: numbers are missing from middle row.  Scale should be reduced.

p97--100 [?] We seem to be being inconsistent in presentation of regex symbols: some of
them are in straight double quotes, a couple (p99, 9d) are in single straight quotes,
and some are not quoted at all. My preference would be for no quotes, or failing
that, double curly quotes.

p98 17up "Chat corpus" -> "NPS Chat Corpus"

p101 "is a loanword" -> "is borrowed from English"

p106 [?] it looks as tho the WN lemmatizer doesn't handle any verb forms.

p113 [?] Ex 3-5: should we add a line to the caption explaining Python's backtick
operator? 

p116 18up with conversion -> with a conversion

p119 4up [?] this is the first mention of lexeme

p120 delete "proc", lowercase "Normalizing"
[?] do we need second mention of Mertz and J&M?

p121 [?] should we give an example of an AI text?
     ex 4: can also specify -> can specify
           [?] we haven't given a value for msg

p122 ex 7: increase point size of subparts 7(a), 7(b)
     [?] ex 8: "clear setting out" doesn't sound v idiomatic
     [?] ex 9(b): companies -> organizations

p123 15up "words corpus" -> "Words Corpus"

p124 [?] ex 27: "500 randomly chosen letters" -- are these meant to be
drawn from the string "aehh "? It's not clear what is meant by
"normalize the whitespace in this string".

     ex 28: "MedLine corpus" -> "MedLine Corpus"

     [?] ex 29:  4.71 Î¼w + 0.5 Î¼s - 21.43 -- should this really be cw?

     [?] ex 31: the variable saying was defined on p118, viz as

     >>> saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',
     ... 'more', 'is', 'said', 'than', 'done', '.']

     Are we expecting readers to pick up on this?

p128 Fig 4-1 caption: foo, bar s/b cw (x 2)

p131 [?] the definitions of all(), any() both look wrong. Firstly, their truth depends
not just on whether there are elts in their args, but whether the elts evaluate to
true. And the defs actually seem to make all() and any() equivalent.

     12up [?] might be better to place the tag [1] after "comma operator", since there
     are no parens in the first line of code.

p133 [?] Para starting "Notice in this code sample..." It looks to me as tho this has
been displaced, and is referring to the code sample in the middle of p132 (i.e. the
one starting >>> raw = "I turned off the spectroroute")

p135 13up lexicon s/b cw, assignment statement shouldn't be split inside variable name

p140 (I previously fixed this as a PDF annotation but it was lost!) 
     "It is tempting to adopt idioms from other  languages,
     when Python offers some elegant and highly readable alternatives."
     -> "It is tempting to adopt idioms from other languages."
     "However, Python offers some elegant and highly readable alternatives,
     as we have seen."

p144 6up "defensive programming" --- maybe this should be introduced as a new
term here (i.e. set in bold) rather than waiting until p157.

p149 17up permutations s/b cw

p150 6up [?] keyword arguments -- treat as new terms?

p151 13up the same function, -> the same function (i.e. omit comma)

p154 Fig 4-2 caption: my_program.py s/b roman

p157 "defensive programming" s/b roman (already introduced term)

p159 eight occurences of numerals on this page s/b non-italic; e.g. in n/2, (n=1)
etc.
     4up 1 s/b proportional font, not cw

p164 tree s/b monochrome, non-terminals s/b boldface

p165 3d previous calls -> previous call

p167 13d rainfall.png -> modals.png

p171 ex 4 assignm0ent -> assignment

p172 delete ex 16 (duplicated from ex 24, p123)

p173 ex 18 the n most: "n" s/b italic, not c/w

     ex 25 NLTK's the Shakespeare -> NLTK's Shakespeare

     ex 26 How -> In what way

     ex 27 The equation for Catalan numbers needs to be set as a math equation (i.e.,
     italicized subscripts); similarly for C_n at end of 27(a).

p174 ex 34 NGramTagger s/b cw

     ex 35 [?] "Read the linked article" -> "Read the following article"
     
p175 n:math -> n

p178 Slanted font for metavariable is correct

p178 [?] What's the issue with the second highlighted section?

p201 General N-Gram Tagging

p208 Please delete the highlighted material in parentheses

p210 lexeme BE -> lexeme be

p217 "anti-ngram" -> "anti-n-gram"

p222 ok to make into a paragraph

p223 "'names' corpus" -> "Names Corpus"

p225 13up "Movie Reviews corpus" -> "Movie Reviews Corpus"

p231 This is meant to be introducing the terms.  The remainder of 
    the paragraph is describing how these three models work in
    general terms.  I recommend the following rewording to make this
    clear:

       Another solution is to assign scores to all of the possible
       sequences of part-of-speech tags, and to choose the sequence
       whose overall score is highest. This is the approach taken by
       <emphasis role="strong">Hidden Markov Models</emphasis>.
       Hidden Markov Models are similar to consecutive classifiers in
       that they look at both the inputs and the history of predicted
       tags. However, rather than simply finding the single best tag
       for a given word, they generate a probability distribution over
       tags. These probabilities are then combined to calculate
       probability scores for tag sequences, and the tag sequence with
       the highest probability is chosen. Unfortunately, the number of
       possible tag sequences is quite large. Given a tag set with 30
       tags, there are about 600 trillion
       (30<superscript>10</superscript>) ways to label a 10-word
       sentence.  In order to avoid considering all these possible
       sequences separately, Hidden Markov Models require that the
       feature extractor only look at the most recent tag (or the most
       recent <emphasis>n</emphasis> tags, where
       <emphasis>n</emphasis> is fairly small). Given that
       restriction, it is possible to use dynamic programming (Section
       4.7) to efficiently find the most likely tag sequence. In
       particular, for each consecutive word index
       <emphasis>i</emphasis>, a score is computed for each possible
       current and previous tag.  This same basic approach is taken by
       two more advanced models, called <emphasis
       role="strong">Maximum Entropy Markov Models</emphasis> and
       <emphasis role="strong">Linear-Chain Conditional Random Field
       Models</emphasis>; but different algorithms are used to find
       scores for tag sequences.

p232 8up "nps_chat corpus" -> "NPS Chat Corpus"

p233 "data set" -> "dataset" (at least 7 times in chapter 6)

p234 Change the paragraph "We let words..." to start:

       In our RTE feature detector (Example 6.7), we let words...

p241 Append the following sentence to the paragraph preceeding example
      6-9 (i.e., the paragraph starting "For example, Figure 6-5 shows.."):

      Example 6-9 demonstrates how to calculate the entropy
      of a list of labels.

p245 Change the sentence "This process is illustrated in
      Figure 6-7" to say "This process is illustrated in Figures
      6-7 and 6-8."

p246 ELE and Heldout Estimation should be marked as definition terms
      (i.e., set in bold), and not quoted.
      -- mention NLTK support for estimation here? -> I don't know if 
         this counts as adding content, but I would be fine with ending
         the paragraph with the sentence "The ``nltk.probability`` module
         provides support for a wide variety of smoothing techniques."
      -- mention ELE and Heldout in further readings section?

p254 Add "the Recognizing Textual Entailment competitions" to this list

p255 5d "names corpus" -> "Names Corpus"

p255 11d "senseval corpus" -> "Senseval 2 Corpus"
     20d "Senseval corpus" -> "Senseval 2 Corpus"

p255 Set in roman, and capitalize "Q": ynQuestion

p256 q9 "Prepositional Phrase Attachment corpus" -> "PP Attachment Corpus"
     "PP attachment corpus" -> "PP Attachment Corpus"

p260 6up "CoNLL-2000 chunking corpus" -> "CoNLL-2000 Chunking Corpus"

p267 18up, 2up "CoNLL 2000 corpus" -> "CoNLL-2000 Chunking Corpus"

p269 14up "CoNLL 2000 corpus" -> "CoNLL-2000 Chunking Corpus"

p275 root node of syntax tree in example (4) s/b boldface

p278 [?] not sure which URLs to give, or where to give them
     - for getty, the wikipedia entry seems best
       http://en.wikipedia.org/wiki/Getty_Thesaurus_of_Geographic_Names
     - for alexandria I don't see anything obvious (should we drop it?)
     - in both cases, the link might be best in the further reading section

p280 3up "conll2002 Dutch corpus" -> "Dutch section of the CoNLL 2002 Named Entity Corpus"

p282 4up "CoNLL corpus" -> "CoNLL-2000 Chunking Corpus"
     "Inspect the CoNLL corpus" -> "Inspect the data"

p283 ex 8 "CoNLL corpus" -> "CoNLL Chunking Corpus"

p284 1d "CoNLL corpus" -> "CoNLL Chunking Corpus"
     
     ex 16 "Penn Treebank" -> "Penn Treebank Corpus"
           "Treebank corpus" -> "Penn Treebank Corpus"

p285 hope we can avoid the widowed lines

p290 non-terminals in the tree diagrams s/b boldface

p293 non-terminals s/b boldface

p302 non-terminals s/b boldface

p302 [?] Delete example (11) and the sentence immediately before it
p303 [?] Delete from top down to and including example (13).
     (I don't think this material elucidates the method;
     it also uses the =>* notation which is not defined afaik) 

p309 [?] not sure what this highlighting of "Dependencies" is about

p311 1up "Penn Treebank corpus" -> "Penn Treebank Corpus"

p312 14up "Prepositional Phrase Attachment Corpus" -> "PP Attachment Corpus"

p313 9d "Sinica Treebank Corpus" s/b roman

p316 change year of Bresnan and Hay citation from 2006 to 2008

p318 [?] (I previously fixed this as a PDF annotation but it was lost!) 

p320 ex 16 "Prepositional Phrase Attachment Corpus" -> "PP Attachment Corpus" 

p321 ex 22 "Prepositional Phrase Attachment Corpus" -> "PP Attachment Corpus"
     ex 28 "Treebank corpus" -> "Penn Treebank Corpus"
     
     [?] like the above, we need to mention this is a sample wherever we mention it 

p328 non-terminals s/b boldface

p329 non-terminals s/b boldface

p332 Fig 9-1 s/b smaller scale

pp334ff directed graphs should be smaller

p351 [?] margin problem

p365 ex (9) [?] alignment and size

p381 ex (29) [?] garbled content, non-terminals s/b boldface

p393 Fig 10-5 [?] screenshot looks weird without a frame (our fault)

p403 11up "TIMIT corpus of read speech" -> "TIMIT Corpus"

p404 12d "TIMIT corpus" -> "TIMIT Corpus"

p404 delete "an", to leave "has internal structure"

p405 ok not to have comma after the word "variables"

p405 1d "TIMIT corpus" -> "TIMIT Corpus"
     1u "TIMIT corpus" -> "TIMIT Corpus"

p406 11d "TIMIT corpus" -> "TIMIT Corpus"

p409 ok not to have comma after the word "window"

p411 agree that GNU WGet should not be italicized

p411 (I previously fixed this as a PDF annotation but it was lost!) 
     "We can enter this in MSWord," -> "We can key in such text using MSWord"

p412 (I previously fixed this as a PDF annotation but it was lost!) 
     "... parts-of-speech as the set difference between used_pos and legal_pos."

p413 ok to delete note about Beautiful Soup package

p417 problem with coordinate structure -- split into two sentences as follows:
     - delete comma after "(SQL)"
     - change comma after "file storage" to period
     - change "and allows" to "It also allows" at start of next sentence

p421 change quoted words "verb" and "noun" to cw, and remove quotes

p429 (I previously fixed this as a PDF annotation but it was lost!)
     "conventions for resource discovery on the Web."
     -> "conventions for finding, sharing, and managing information." 

p433 1d, 2d delete braces around BNC and TLG

p433 add URL http://www.python.org/doc/lib/markup.html

p435 adopt proposed replacement text

p440 (I previously fixed this as a PDF annotation but it was lost!)
     Add: "Contributions in the following areas are particularly encouraged:"

p443ff [?] Bracketted author year information in bibliography entries is
     redundant and looks rather ugly -- can we omit this?
     First author's name should be formatted as "Lastname, Firstname"
     
p444 "Ca" -> "CA" (California)

p444 Replace Bresnan and Hay citation with published version: (italicize "give")

     Joan Bresnan and Jennifer Hay.
       Gradient grammar: An effect of animacy on the syntax of *****give*****
       in New Zealand and American English. Lingua 118: 245Ð59, 2008  
